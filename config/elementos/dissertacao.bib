
@book{hyndman_forecasting_2021,
	location = {Melbourne, Austrália},
	edition = {3},
	title = {Forecasting: principles and practice},
	url = {https://otexts.com/fpp3/},
	publisher = {{OTexts}},
	author = {Hyndman, R.J. and Athanasopoulos, G},
	date = {2021},
}

@article{mancuso_machine_2021,
	title = {A machine learning approach for forecasting hierarchical time series},
	volume = {182},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421005431},
	doi = {10.1016/j.eswa.2021.115102},
	abstract = {In this paper, we propose a machine learning approach for forecasting hierarchical time series. When dealing with hierarchical time series, apart from generating accurate forecasts, one needs to select a suitable method for producing reconciled forecasts. Forecast reconciliation is the process of adjusting forecasts to make them coherent across the hierarchy. In literature, coherence is often enforced by using a post-processing technique on the base forecasts produced by suitable time series forecasting methods. On the contrary, our idea is to use a deep neural network to directly produce accurate and reconciled forecasts. We exploit the ability of a deep neural network to extract information capturing the structure of the hierarchy. We impose the reconciliation at training time by minimizing a customized loss function. In many practical applications, besides time series data, hier­ archical time series include explanatory variables that are beneficial for increasing the forecasting accuracy. Exploiting this further information, our approach links the relationship between time series features extracted at any level of the hierarchy and the explanatory variables into an end-to-end neural network providing accurate and reconciled point forecasts. The effectiveness of the approach is validated on three real-world datasets, where our method outperforms state-of-the-art competitors in hierarchical forecasting.},
	pages = {115102},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Mancuso, Paolo and Piccialli, Veronica and Sudoso, Antonio M.},
	urldate = {2023-01-10},
	date = {2021-11},
	langid = {english},
	file = {Mancuso et al. - 2021 - A machine learning approach for forecasting hierar.pdf:C\:\\Users\\alber\\Zotero\\storage\\CP9W5HPY\\Mancuso et al. - 2021 - A machine learning approach for forecasting hierar.pdf:application/pdf},
}

@article{abolghasemi_machine_2022,
	title = {Machine learning applications in hierarchical time series forecasting: Investigating the impact of promotions},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207022001029},
	doi = {10.1016/j.ijforecast.2022.07.004},
	shorttitle = {Machine learning applications in hierarchical time series forecasting},
	abstract = {Hierarchical forecasting is needed in many situations in the supply chain to support decision making. Top-down, bottom-up, and optimal linear combination methods are common in hierarchical forecasting. There is no universally optimal solution for hierarchical forecasting, and each method has some advantages and disadvantages. While top-down and bottom-up methods use only the information at the top and bottom levels, respectively, linear combinations use the individual sales forecasts from all series and levels and combine them linearly, often outperforming the conventional top-down and bottom-up methods. These methods do not directly utilise the explanatory information such as price and promotion status that may be available across different levels in the hierarchy, and their performance may be impacted by these external factors. We propose to use a multi-output regression model that utilises the explanatory variables from across hierarchical levels to simultaneously generate forecasts for all the series at the bottom level. We perform an in-depth analysis of 55 sets of fast-moving consumer goods time series and 3049 products of the M5 forecasting competition data. Our results show that our proposed algorithm effectively utilises explanatory variables from across the hierarchy to generate reliable forecasts for different hierarchical levels, especially in the presence of deep promotional discounts.},
	pages = {S0169207022001029},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Abolghasemi, Mahdi and Tarr, Garth and Bergmeir, Christoph},
	urldate = {2023-01-10},
	date = {2022-08},
	langid = {english},
	file = {Abolghasemi et al. - 2022 - Machine learning applications in hierarchical time.pdf:C\:\\Users\\alber\\Zotero\\storage\\2LYBKZU4\\Abolghasemi et al. - 2022 - Machine learning applications in hierarchical time.pdf:application/pdf},
}

@article{athanasopoulos_hierarchical_2009,
	title = {Hierarchical forecasts for Australian domestic tourism},
	volume = {25},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207008000691},
	doi = {10.1016/j.ijforecast.2008.07.004},
	abstract = {In this paper we explore the hierarchical nature of tourism demand time series and produce short-term forecasts for Australian domestic tourism. The data and forecasts are organized in a hierarchy based on disaggregating the data according to geographical regions and purposes of travel. We consider five approaches to hierarchical forecasting: two variations of the top-down approach, the bottom-up method, a newly proposed top-down approach where top-level forecasts are disaggregated according to the forecasted proportions of lower level series, and a recently proposed optimal combination approach. Our forecast performance evaluation shows that the top-down approach based on forecast proportions and the optimal combination method perform best for the tourism hierarchies we consider. By applying these methods, we produce detailed forecasts of the Australian domestic tourism market.},
	pages = {146--166},
	number = {1},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Athanasopoulos, George and Ahmed, Roman A. and Hyndman, Rob J.},
	urldate = {2023-01-11},
	date = {2009-01-01},
	langid = {english},
	keywords = {Australia, Exponential smoothing, Hierarchical forecasting, Innovations state space models, Optimal combination forecasts, Top-down method, Tourism demand},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\J8W83JR3\\S0169207008000691.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\4BUP4JD8\\Athanasopoulos et al. - 2009 - Hierarchical forecasts for Australian domestic tou.pdf:application/pdf},
}

@article{athanasopoulos_forecasting_2017,
	title = {Forecasting with temporal hierarchies},
	volume = {262},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221717301911},
	doi = {10.1016/j.ejor.2017.02.046},
	abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied combination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short-term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that forecasting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident \& Emergency departments.},
	pages = {60--74},
	number = {1},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Athanasopoulos, George and Hyndman, Rob J. and Kourentzes, Nikolaos and Petropoulos, Fotios},
	urldate = {2023-01-11},
	date = {2017-10-01},
	langid = {english},
	keywords = {Hierarchical forecasting, Forecast combination, Forecasting, Reconciliation, Temporal aggregation},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\WZJBQ4VM\\S0377221717301911.html:text/html;Texto completo:C\:\\Users\\alber\\Zotero\\storage\\Y46S5248\\Athanasopoulos et al. - 2017 - Forecasting with temporal hierarchies.pdf:application/pdf},
}

@article{hyndman_optimal_2011,
	title = {Optimal combination forecasts for hierarchical time series},
	volume = {55},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947311000971},
	doi = {10.1016/j.csda.2011.03.006},
	abstract = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these “hierarchical time series”. They are commonly forecast using either a “bottom-up” or a “top-down” method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region.},
	pages = {2579--2589},
	number = {9},
	journaltitle = {Computational Statistics \& Data Analysis},
	shortjournal = {Computational Statistics \& Data Analysis},
	author = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
	urldate = {2023-01-11},
	date = {2011-09-01},
	langid = {english},
	keywords = {Hierarchical forecasting, Bottom-up forecasting, Combining forecasts, {GLS} regression, Reconciling forecasts, Top-down forecasting},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\9STYZZ2I\\S0167947311000971.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\RC5BPNMH\\Hyndman et al. - 2011 - Optimal combination forecasts for hierarchical tim.pdf:application/pdf},
}

@article{hyndman_fast_2016,
	title = {Fast computation of reconciled forecasts for hierarchical and grouped time series},
	volume = {97},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S016794731500290X},
	doi = {10.1016/j.csda.2015.11.007},
	abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
	pages = {16--32},
	journaltitle = {Computational Statistics \& Data Analysis},
	shortjournal = {Computational Statistics \& Data Analysis},
	author = {Hyndman, Rob J. and Lee, Alan J. and Wang, Earo},
	urldate = {2023-01-11},
	date = {2016-05-01},
	langid = {english},
	keywords = {Combining forecasts, Reconciling forecasts, Grouped time series, Hierarchical time series, Weighted least squares},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\7CFRT5LZ\\S016794731500290X.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\BGW6W29K\\Hyndman et al. - 2016 - Fast computation of reconciled forecasts for hiera.pdf:application/pdf},
}

@article{kourentzes_cross-temporal_2019,
	title = {Cross-temporal coherent forecasts for Australian tourism},
	volume = {75},
	issn = {0160-7383},
	url = {https://www.sciencedirect.com/science/article/pii/S0160738319300167},
	doi = {10.1016/j.annals.2019.02.001},
	abstract = {Key to ensuring a successful tourism sector is timely policy making and detailed planning. National policy formulation and strategic planning requires long-term forecasts at an aggregate level, while regional operational decisions require short-term forecasts, relevant to local tourism operators. For aligned decisions at all levels, supporting forecasts must be ‘coherent’, that is they should add up appropriately, across relevant demarcations (e.g., geographical divisions or market segments) and also across time. We propose an approach for generating coherent forecasts across both cross-sections and planning horizons for Australia. This results in significant improvements in forecast accuracy with substantial decision making benefits. Coherent forecasts help break intra- and inter-organisational information and planning silos, in a data driven fashion, blending information from different sources. This article also launches the Annals of Tourism Research Curated Collection on Tourism Demand Forecast, a special selection of research in this field.},
	pages = {393--409},
	journaltitle = {Annals of Tourism Research},
	shortjournal = {Annals of Tourism Research},
	author = {Kourentzes, Nikolaos and Athanasopoulos, George},
	urldate = {2023-01-11},
	date = {2019-03-01},
	langid = {english},
	keywords = {Temporal aggregation, Cross-sectional aggregation, Forecast combinations, Spatial correlations},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\XWJHQIV5\\S0160738319300167.html:text/html;Versão aceita:C\:\\Users\\alber\\Zotero\\storage\\VLLGLPYE\\Kourentzes e Athanasopoulos - 2019 - Cross-temporal coherent forecasts for Australian t.pdf:application/pdf},
}

@article{spiliotis_hierarchical_2021,
	title = {Hierarchical forecast reconciliation with machine learning},
	volume = {112},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494621006773},
	doi = {10.1016/j.asoc.2021.107756},
	abstract = {Over the last 15 years, studies on hierarchical forecasting have moved away from single-level approaches towards proposing linear combination approaches across multiple levels of the hierarchy. Such combinations offer coherent reconciled forecasts, improved forecasting performance and aligned decision-making. This paper proposes a novel hierarchical forecasting approach based on machine learning. The proposed method allows for non-linear combinations of the base forecasts, thus being more general than linear approaches. We structurally combine the objectives of improved post-sample empirical forecasting accuracy and coherence. Due to its non-linear nature, our approach selectively combines the base forecasts in a direct and automated way without requiring that the complete information must be used for producing reconciled forecasts for each series and level. The proposed method is evaluated both in terms of accuracy and bias using two different data sets coming from the tourism and retail industries. Our results suggest that the proposed method gives superior point forecasts than existing approaches, especially when the series comprising the hierarchy are not characterized by the same patterns.},
	pages = {107756},
	journaltitle = {Applied Soft Computing},
	shortjournal = {Applied Soft Computing},
	author = {Spiliotis, Evangelos and Abolghasemi, Mahdi and Hyndman, Rob J. and Petropoulos, Fotios and Assimakopoulos, Vassilios},
	urldate = {2023-01-11},
	date = {2021-11-01},
	langid = {english},
	keywords = {Forecasting, Hierarchies, Non-linear coherence, Time series},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\5FEV4WJF\\S1568494621006773.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\BHCIDFV2\\Spiliotis et al. - 2021 - Hierarchical forecast reconciliation with machine .pdf:application/pdf},
}

@article{panagiotelis_forecast_2021,
	title = {Forecast reconciliation: A geometric view with new insights on bias correction},
	volume = {37},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207020300911},
	doi = {10.1016/j.ijforecast.2020.06.004},
	shorttitle = {Forecast reconciliation},
	abstract = {A geometric interpretation is developed for so-called reconciliation methodologies used to forecast time series that adhere to known linear constraints. In particular, a general framework is established that nests many existing popular reconciliation methods within the class of projections. This interpretation facilitates the derivation of novel theoretical results. First, reconciliation via projection is guaranteed to improve forecast accuracy with respect to a class of loss functions based on a generalised distance metric. Second, the Minimum Trace ({MinT}) method minimises expected loss for this same class of loss functions. Third, the geometric interpretation provides a new proof that forecast reconciliation using projections results in unbiased forecasts, provided that the initial base forecasts are also unbiased. Approaches for dealing with biased base forecasts are proposed. An extensive empirical study of Australian tourism flows demonstrates the theoretical results of the paper and shows that bias correction prior to reconciliation outperforms alternatives that only bias-correct or only reconcile forecasts.},
	pages = {343--359},
	number = {1},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Panagiotelis, Anastasios and Athanasopoulos, George and Gamakumara, Puwasala and Hyndman, Rob J.},
	urldate = {2023-01-15},
	date = {2021-01-01},
	langid = {english},
	keywords = {Elliptical distributions, Forecast reconciliation, High-dimensional time series, Projections, Scoring rules},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\NIGZCW7Z\\S0169207020300911.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\I8K5Z6CB\\Panagiotelis et al. - 2021 - Forecast reconciliation A geometric view with new.pdf:application/pdf},
}

@inproceedings{ben_taieb_regularized_2019,
	location = {New York, {NY}, {USA}},
	title = {Regularized Regression for Hierarchical Forecasting Without Unbiasedness Conditions},
	isbn = {978-1-4503-6201-6},
	url = {https://doi.org/10.1145/3292500.3330976},
	doi = {10.1145/3292500.3330976},
	series = {{KDD} '19},
	abstract = {Forecasting a large set of time series with hierarchical aggregation constraints is a central problem for many organizations. However, it is particularly challenging to forecast these hierarchical structures. In fact, it requires not only good forecast accuracy at each level of the hierarchy, but also the coherency between different levels, i.e. the forecasts should satisfy the hierarchical aggregation constraints. Given some incoherent base forecasts, the state-of-the-art methods compute revised forecasts based on forecast combination which ensures that the aggregation constraints are satisfied. However, these methods assume the base forecasts are unbiased and constrain the revised forecasts to be also unbiased. We propose a new forecasting method which relaxes these unbiasedness conditions, and seeks the revised forecasts with the best tradeoff between bias and forecast variance. We also present a regularization method which allows us to deal with high-dimensional hierarchies, and provide its theoretical justification. Finally, we compare the proposed method with the state-of-the-art methods both theoretically and empirically. The results on both simulated and real-world data indicate that our methods provide competitive results compared to the state-of-the-art methods.},
	pages = {1337--1347},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery \& Data Mining},
	publisher = {Association for Computing Machinery},
	author = {Ben Taieb, Souhaib and Koo, Bonsoo},
	urldate = {2023-02-20},
	date = {2019-07-25},
	keywords = {hierarchical forecasting, regularization, sparsity, time series},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\CTLSN8MT\\Ben Taieb e Koo - 2019 - Regularized Regression for Hierarchical Forecastin.pdf:application/pdf},
}

@article{gorodetskaya_machine_2021,
	title = {A Machine Learning Pipeline for Forecasting Time Series in the Banking Sector},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7099},
	url = {https://www.mdpi.com/2227-7099/9/4/205},
	doi = {10.3390/economies9040205},
	abstract = {The problem of forecasting time series is very widely debated. In recent years, machine learning algorithms have been very prolific in this area. This paper describes a systematic approach to building a machine learning predictive model for solving optimization problems in the banking sector. A literature analysis on applying such methods in this particular area is presented. As a direct result of the described research, a universal scenario for forecasting various non-stationary time series in automatic mode was developed. The developed scenario for solving specific banking tasks to improve business efficiency, including optimizing demand for {ATMs}, forecasting the load on the call center and cash center, is considered. A machine learning methodology in economics that can yield robust and reproducible results and can be reused in solving other similar tasks is described. The methodology described in the article was tested on three cases and showed the ability to generate models that are superior in accuracy to similar predictive models described in the literature by at least three percentage points. This article will be helpful to specialists dealing with the problem of forecasting economic time series and students and researchers due to a large number of links to systematic literature reviews on this topic.},
	pages = {205},
	number = {4},
	journaltitle = {Economies},
	author = {Gorodetskaya, Olga and Gobareva, Yana and Koroteev, Mikhail},
	urldate = {2023-02-27},
	date = {2021-12},
	langid = {english},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial neural networks, {ATMs}, data mining, load forecasting, machine learning, service optimization, time series forecasting},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\K794F59A\\Gorodetskaya et al. - 2021 - A Machine Learning Pipeline for Forecasting Time S.pdf:application/pdf},
}

@report{colak_tcmb_2019,
	location = {Ankara, Turquia},
	title = {{TCMB} - Monitoring and Forecasting Cyclical Dynamics in Bank Credits: Evidence from Turkish Banking Sector},
	url = {https://www.tcmb.gov.tr/wps/wcm/connect/EN/TCMB+EN/Main+Menu/Publications/Research/Working+Paperss/2019/19-29},
	shorttitle = {{TCMB} - Monitoring and Forecasting Cyclical Dynamics in Bank Credits},
	abstract = {The Central Bank of the Republic of Turkey is responsible for the monetary and exchange rate policies in Turkey. The primary objective of the Bank is to achieve price stability.},
	institution = {Banco Central da República da Turquia},
	author = {Çolak, Mehmet Selman and Güney, İbrahim Ethem and Şenol, Ahmet and Yilmaz, Muhammed Hasan},
	urldate = {2023-03-06},
	date = {2019},
	langid = {english},
	file = {Snapshot:C\:\\Users\\alber\\Zotero\\storage\\6H5T3WQK\\19-29.html:text/html;wp1929.pdf:C\:\\Users\\alber\\Zotero\\storage\\HSIYHGXU\\wp1929.pdf:application/pdf},
}

@article{prayoga_top-down_2017,
	title = {Top-down forecasting for high dimensional currency circulation data of Bank Indonesia},
	volume = {9},
	abstract = {This paper provides a solution for forecasting high dimensional time series, in the case of currency circulation in Indonesia . Currency circulation data are divided to currency inflow and outflow. Each of them are treated as hierarchical time series separately. The top-down method is applied based on historical proportion, thus only the total series of inflow and outflow need to be modeled. We have compared the implementation of some time series models in top-down forecasting, including Naïve, decomposition, Winters', {ARIMA}, and two levels {ARIMAX} with Eid al-Fitr effect. Each model was specified with varying type of proportion and historical period for calculating the proportions. The results showed that the best method is top-down method with historical proportions type 2 that use the forecast of Naïve method. The proportions are best calculated by using historical data from the last 12 months.},
	pages = {62--74},
	journaltitle = {International Journal of Advances in Soft Computing and its Applications},
	shortjournal = {International Journal of Advances in Soft Computing and its Applications},
	author = {Prayoga, I.G.S.A. and Suhartono, Suhartono and Rahayu, S.P.},
	date = {2017-01-01},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\AU6LZRE6\\Prayoga et al. - 2017 - Top-down forecasting for high dimensional currency.pdf:application/pdf},
}

@thesis{prayoga_hierarchical_2016,
	location = {Surabaya},
	title = {Hierarchical Forecasting of Currency Inflow and Outflow in Bank Indonesia Based on Hybrid Arimax-Ann Model},
	institution = {{INSTITUT} {TEKNOLOGI} {SEPULUH} {NOPEMBER}},
	type = {Mestrado},
	author = {Prayoga, I Gede Surya Adi},
	date = {2016},
	langid = {english},
	file = {Rahayu e Si - 2016 - SUPERVISORS Dr. Suhartono, M.Sc..pdf:C\:\\Users\\alber\\Zotero\\storage\\9SNV8A6H\\Rahayu e Si - 2016 - SUPERVISORS Dr. Suhartono, M.Sc..pdf:application/pdf},
}

@article{bader_modelo_2014,
	title = {Modelo favar canônico para previsão do mercado de crédito},
	volume = {369},
	issn = {1519-1028},
	abstract = {O presente estudo propõe uma nova metodologia denominada {FAVAR} canônico que incorpora uma etapa de análise de correlação canônica na estimação dos modelos {FAVAR} em 2 estágios como uma forma de obter fatores mais adequados à previsão. A técnica de correlação canônica é usada para identificar um pequeno número de combinações lineares de componentes principais que tem melhor correlação com as variáveis de interesse e, portanto, maior capacidade preditiva. O {FAVAR} canônico foi aplicado na previsão de variáveis de crédito do sistema financeiro brasileiro e a sua capacidade preditiva foi comparada à dos modelos {FAVAR} em 1 e 2 estágios. Foram ajustados modelos para 5 variáveis do mercado de crédito brasileiro, tendo sido observado resultados superiores aos obtidos pelos tradicionais modelos {FAVAR}.},
	pages = {38},
	journaltitle = {Banco Central do Brasil},
	author = {Bader, Fani Lea Cymrot and {Koyama, Sérgio Mikio} and {Tsuchida, Marcos Hiroyuki}},
	date = {2014-11},
	langid = {portuguese},
	file = {Bader - Modelo FAVAR Canônico para Previsão do Mercado de .pdf:C\:\\Users\\alber\\Zotero\\storage\\7JQSX5ID\\Bader - Modelo FAVAR Canônico para Previsão do Mercado de .pdf:application/pdf},
}

@book{hastie_elements_2009,
	location = {New York, {NY}},
	edition = {2nd 2009, Corr. 9th Printing 2017 ed. edição},
	title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition},
	isbn = {978-0-387-84857-0},
	shorttitle = {The Elements of Statistical Learning},
	abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates.},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	date = {2009-02-01},
	file = {Hastie et al. - 2009 - The Elements of Statistical Learning Data Mining,.pdf:C\:\\Users\\alber\\Zotero\\storage\\AZRYIXKU\\Hastie et al. - 2009 - The Elements of Statistical Learning Data Mining,.pdf:application/pdf},
}

@misc{sezer_financial_2019,
	location = {Turquia},
	title = {Financial Time Series Forecasting with Deep Learning : A Systematic Literature Review: 2005-2019},
	url = {http://arxiv.org/abs/1911.13288},
	shorttitle = {Financial Time Series Forecasting with Deep Learning},
	abstract = {Financial time series forecasting is, without a doubt, the top choice of computational intelligence for finance researchers from both academia and financial industry due to its broad implementation areas and substantial impact. Machine Learning ({ML}) researchers came up with various models and a vast number of studies have been published accordingly. As such, a significant amount of surveys exist covering {ML} for financial time series forecasting studies. Lately, Deep Learning ({DL}) models started appearing within the field, with results that significantly outperform traditional {ML} counterparts. Even though there is a growing interest in developing models for financial time series forecasting research, there is a lack of review papers that were solely focused on {DL} for finance. Hence, our motivation in this paper is to provide a comprehensive literature review on {DL} studies for financial time series forecasting implementations. We not only categorized the studies according to their intended forecasting implementation areas, such as index, forex, commodity forecasting, but also grouped them based on their {DL} model choices, such as Convolutional Neural Networks ({CNNs}), Deep Belief Networks ({DBNs}), Long-Short Term Memory ({LSTM}). We also tried to envision the future for the field by highlighting the possible setbacks and opportunities, so the interested researchers can benefit.},
	number = {{arXiv}:1911.13288},
	publisher = {{arXiv}},
	author = {Sezer, Omer Berat and Gudelek, Mehmet Ugur and Ozbayoglu, Ahmet Murat},
	urldate = {2023-03-07},
	date = {2019-11-29},
	eprinttype = {arxiv},
	eprint = {1911.13288 [cs, q-fin, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, I.1.2, Quantitative Finance - Computational Finance},
	file = {arXiv Fulltext PDF:C\:\\Users\\alber\\Zotero\\storage\\6EAFRQYZ\\Sezer et al. - 2019 - Financial Time Series Forecasting with Deep Learni.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alber\\Zotero\\storage\\5AB5SAK2\\1911.html:text/html},
}

@article{li_hierarchical_2016,
	title = {A Hierarchical Approach Using Machine Learning Methods in Solar Photovoltaic Energy Production Forecasting},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/9/1/55},
	doi = {10.3390/en9010055},
	abstract = {We evaluate and compare two common methods, artificial neural networks ({ANN}) and support vector regression ({SVR}), for predicting energy productions from a solar photovoltaic ({PV}) system in Florida 15 min, 1 h and 24 h ahead of time. A hierarchical approach is proposed based on the machine learning algorithms tested. The production data used in this work corresponds to 15 min averaged power measurements collected from 2014. The accuracy of the model is determined using computing error statistics such as mean bias error ({MBE}), mean absolute error ({MAE}), root mean square error ({RMSE}), relative {MBE} ({rMBE}), mean percentage error ({MPE}) and relative {RMSE} ({rRMSE}). This work provides findings on how forecasts from individual inverters will improve the total solar power generation forecast of the {PV} system.},
	pages = {55},
	number = {1},
	journaltitle = {Energies},
	author = {Li, Zhaoxuan and Rahman, {SM} Mahbobur and Vega, Rolando and Dong, Bing},
	urldate = {2023-04-08},
	date = {2016-01},
	langid = {english},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial neural network ({ANN}), photovoltaic ({PV}) forecasting, support vector regression ({SVR})},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\GHT9A3XQ\\Li et al. - 2016 - A Hierarchical Approach Using Machine Learning Met.pdf:application/pdf},
}

@article{beccalli_earnings_2015,
	title = {Earnings management, forecast guidance and the banking crisis},
	volume = {21},
	issn = {1351-847X},
	url = {https://doi.org/10.1080/1351847X.2013.809548},
	doi = {10.1080/1351847X.2013.809548},
	abstract = {This paper studies earnings management ({EM}) and forecast guidance ({FG}) activities of European banks between 2004 and 2008. Using 22,564 analyst forecasts for 55 banks, we find that the proportion of banks hitting or beating analyst consensus fell from 68.22\% pre-crisis to 28.13\% during the crisis. Banks enjoy higher cumulative adjusted returns ({CARs}) when they hit analyst consensus only in the crisis. {EM} is evident pre- but not during the crisis – it has no {CAR} effects. {FG} increases the probability of hitting benchmark earnings and during the crisis yields higher {CARs}. {EM} and {FG} act as complements in the crisis period.},
	pages = {242--268},
	number = {3},
	journaltitle = {The European Journal of Finance},
	author = {Beccalli, Elena and Bozzolan, Saverio and Menini, Andrea and Molyneux, Philip},
	urldate = {2023-05-07},
	date = {2015-02-19},
	keywords = {analyst earnings forecast, banks, crisis, earnings management, forecasts guidance, G21, M41},
	file = {Texto completo:C\:\\Users\\alber\\Zotero\\storage\\7SQIVWXY\\Beccalli et al. - 2015 - Earnings management, forecast guidance and the ban.pdf:application/pdf},
}

@article{wallander_budgeting_1999,
	title = {Budgeting — an unnecessary evil},
	volume = {15},
	issn = {0956-5221},
	url = {https://www.sciencedirect.com/science/article/pii/S0956522198000323},
	doi = {10.1016/S0956-5221(98)00032-3},
	abstract = {Almost 30 years ago — in 1970 — the largest commercial bank in Sweden, Handelsbanken, was in a major crisis. Profitability was low and the bank was in conflict with the authorities. As a result of the crisis the executive director left the bank, as did several of the top officials. At this point the board of the bank asked me to become executive director. At that time I was head of a provincial bank in the northern part of Sweden – Sundsvallsbanken. I had been at that bank for ten years. Before that I was a professional economist, head of a major research institute and an associate professor at the University of Stockholm. I did not have any practical business experience and knew nothing about banking, but after 10 years in Sundsvallsbanken, I had learned a lot and developed some firm ideas about how to run a bank with a large network of branch offices.},
	pages = {405--421},
	number = {4},
	journaltitle = {Scandinavian Journal of Management},
	shortjournal = {Scandinavian Journal of Management},
	author = {Wallander, Jan},
	urldate = {2023-05-08},
	date = {1999-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\EJUBXBBW\\S0956522198000323.html:text/html;Texto completo:C\:\\Users\\alber\\Zotero\\storage\\GTCR4IG5\\Wallander - 1999 - Budgeting — an unnecessary evil.pdf:application/pdf},
}

@misc{conselho_monetario_nacional_resolucao_1994,
	location = {Brasília, {DF}},
	title = {Resolução nº 2.099, de 17 de agosto de 1994},
	url = {https://www.bcb.gov.br/pre/normativos/res/1994/pdf/res_2099_v1_O.pdf},
	abstract = {Aprova regulamentos que dispõem sobre as 
condições relativamente ao acesso ao Sistema
Financeiro Nacional, aos valores mínimos de 
capital e patrimônio líquido ajustado, à 
instalação de dependências e à obrigatoriedade 
da manutenção de patrimônio líquido ajustado
em valor compatível com o grau de risco das
operações ativas das instituições financeiras e 
demais instituições autorizadas a funcionar 
pelo Banco Central.},
	publisher = {Banco Central do Brasil},
	author = {{Conselho Monetário Nacional}},
	date = {1994-08-17},
}

@misc{brasil_lei_1986,
	location = {Brasília, {DF}},
	title = {Lei nº 7.492, de 16 de junho de 1986},
	url = {https://www.planalto.gov.br/ccivil_03/leis/l7492.htm},
	abstract = {Define os crimes contra o Sistema Financeiro nacional e dá outras providências},
	publisher = {Presidência da República},
	author = {{Brasil}},
	date = {1986-06-18},
}

@article{bergmeir_note_2018,
	title = {A note on the validity of cross-validation for evaluating autoregressive time series prediction},
	volume = {120},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947317302384},
	doi = {10.1016/j.csda.2017.11.003},
	pages = {70--83},
	journaltitle = {Computational Statistics \& Data Analysis},
	shortjournal = {Computational Statistics \& Data Analysis},
	author = {Bergmeir, Christoph and Hyndman, Rob J. and Koo, Bonsoo},
	urldate = {2023-05-28},
	date = {2018-04},
	langid = {english},
	file = {Texto completo:C\:\\Users\\alber\\Zotero\\storage\\2B6MNXE8\\Bergmeir et al. - 2018 - A note on the validity of cross-validation for eva.pdf:application/pdf},
}

@article{stone_cross-validation_1974,
	title = {Cross-validation and multinomial prediction},
	volume = {61},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/61.3.509},
	doi = {10.1093/biomet/61.3.509},
	abstract = {The method of cross-validatory choice and assessment is applied to prediction of a multinomial indicator. The resulting predictor is compared with analogous expressions due to Good and Fienberg \&amp; Holland. Some numerical comparisons are made.},
	pages = {509--515},
	number = {3},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {Stone, M.},
	urldate = {2023-05-28},
	date = {1974-12-01},
	file = {Snapshot:C\:\\Users\\alber\\Zotero\\storage\\QCN6KN4J\\249386.html:text/html;Texto completo:C\:\\Users\\alber\\Zotero\\storage\\S53DVXWK\\STONE - 1974 - Cross-validation and multinomial prediction.pdf:application/pdf},
}

@article{bergmeir_use_2012,
	title = {On the use of cross-validation for time series predictor evaluation},
	volume = {191},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025511006773},
	doi = {10.1016/j.ins.2011.12.028},
	series = {Data Mining for Software Trustworthiness},
	abstract = {In time series predictor evaluation, we observe that with respect to the model selection procedure there is a gap between evaluation of traditional forecasting procedures, on the one hand, and evaluation of machine learning techniques on the other hand. In traditional forecasting, it is common practice to reserve a part from the end of each time series for testing, and to use the rest of the series for training. Thus it is not made full use of the data, but theoretical problems with respect to temporal evolutionary effects and dependencies within the data as well as practical problems regarding missing values are eliminated. On the other hand, when evaluating machine learning and other regression methods used for time series forecasting, often cross-validation is used for evaluation, paying little attention to the fact that those theoretical problems invalidate the fundamental assumptions of cross-validation. To close this gap and examine the consequences of different model selection procedures in practice, we have developed a rigorous and extensive empirical study. Six different model selection procedures, based on (i) cross-validation and (ii) evaluation using the series’ last part, are used to assess the performance of four machine learning and other regression techniques on synthetic and real-world time series. No practical consequences of the theoretical flaws were found during our study, but the use of cross-validation techniques led to a more robust model selection. To make use of the “best of both worlds”, we suggest that the use of a blocked form of cross-validation for time series evaluation became the standard procedure, thus using all available information and circumventing the theoretical problems.},
	pages = {192--213},
	journaltitle = {Information Sciences},
	shortjournal = {Information Sciences},
	author = {Bergmeir, Christoph and Benítez, José M.},
	urldate = {2023-05-30},
	date = {2012-05-15},
	langid = {english},
	keywords = {Time series, Cross-validation, Error measures, Machine learning, Predictor evaluation, Regression},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\G89ZF9YW\\S0020025511006773.html:text/html;Texto completo:C\:\\Users\\alber\\Zotero\\storage\\I5RR5MFT\\Bergmeir e Benítez - 2012 - On the use of cross-validation for time series pre.pdf:application/pdf},
}

@article{coelho_responsabilidade_2015,
	title = {A responsabilidade da auditoria externa na fraude contábil do banco panamericano},
	volume = {3},
	rights = {Copyright (c) 2015 {RAGC}},
	issn = {2317-0484},
	url = {https://revistas.fucamp.edu.br/index.php/ragc/article/view/604},
	abstract = {O objetivo do presente estudo foi analisar a responsabilidade da auditoria externa correspondente à fraude contábil revelada no Banco {PanAmericano}. Fraude essa que foi descoberta pelo Banco Central no ano de 2010. Para a realização da pesquisa utilizou-se de fontes primárias e secundárias, adotando como pressuposto para análise empírica e posteriores evidenciações os balanços anunciados, pareceres de auditoria e noticiários em fontes primárias e jornalísticas, em virtude da limitação de estudos científicos encontrados ao escopo de pesquisa, fraude contábil no Banco {PanAmericano}. A classificação metodológica da pesquisa foi de ordem exploratória com abordagem qualitativa. Os resultados demonstraram que, embora a fraude fosse difícil de ser descoberta a empresa de auditoria externa Delloite poderia ter se esforçado mais na busca de respostas quanto às demonstrações contábeis, ou ao menos ter exposto os seus limites e dificuldades quanto à análise dessas demonstrações através de um parecer com ressalvas. Espera-se que com o presente estudo possa contribuir para o estudo de fraudes, do por que elas acontecem, de suas características, assim como a atuação da auditoria interna e externa em tais casos, e também proporcionar uma reflexão quanto à responsabilidade do auditor nesse tipo situação. Palavras chave: Auditoria externa. Fraudes Contábeis. Responsabilidade do auditor.},
	number = {7},
	journaltitle = {{RAGC}},
	author = {Coelho, Arthur Nascimento Bernardes and Lima, Nilton Cesar and Souza, Gustavo Henrique Silva and Oliveira, Sonia Valle Walter Borges and Oliveira, Márcio Mattos Borges},
	urldate = {2023-05-31},
	date = {2015-09-02},
	langid = {portuguese},
	note = {Number: 7},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\D222WL72\\Coelho et al. - 2015 - A RESPONSABILIDADE DA AUDITORIA EXTERNA NA FRAUDE .pdf:application/pdf},
}

@thesis{moura_alise_2007,
	location = {Rio de Janeiro},
	title = {Análise dos fatores de convencimento do juízo brasileiro quanto à ocorrência de fraude contábil: um estudo de caso Múltiplo da Gallus, da Encol e do Banco Santos},
	url = {http://bibliotecadigital.fgv.br:80/dspace/handle/10438/4038},
	shorttitle = {Análise dos fatores de convencimento do juízo brasileiro quanto à ocorrência de fraude contábil},
	abstract = {This work is based on the analysis of three Brazilian cases of condemnation by accounting fraud and financial reports manipulation of data, where we tried to identify if there is condemnation by accounting fraud in Brazil and the main factors considered by the judge to convince them about the accounting fraud. The theoretical reference quoted involves the theory of fraud, the psychology of fraud, examples of financial fraud in foreign companies and Brazilians banks and the law in Brazil regarding fraud and money laundering. The methodology consisted in studies of Brazilian cases with the data collection criteria from three law suits. The methodology used was the Contents Analysis The samples were chosen according to the impact those cases had in Brazil and the facility to access their law suits. Therefore, we chose Gallus Agropecuária S/A, Encol S/A and Banco Santos S/A for a matter of convenience. The evidence indicated that in those three cases, the court was convinced by the accounting fraud due to omission of relevant financial information in the balance sheet, by information provided to the market that didn¿t reflect the healthy of the company (assets written up without the property). It was identified as well that, in those three cases, there was condemnation not only for the accounting fraud per si, but also by the combination of other crimes as money laundering, fraud gang, material and ideological false fraud, and bankruptcy.},
	institution = {Fundação Getúlio Vargas},
	type = {Dissertação de mestrado},
	author = {Moura, Denia de},
	urldate = {2023-05-31},
	date = {2007},
	note = {Accepted: 2009-11-18T19:01:34Z},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\F4VZE6Z7\\Moura - 2007 - Análise dos fatores de convencimento do juízo bras.pdf:application/pdf},
}

@misc{conselho_monetario_nacional_resolucao_1999,
	location = {Brasília, {DF}},
	title = {Resolução nº 2.682, de 21 de dezembro de 1999},
	url = {https://www.bcb.gov.br/pre/normativos/res/1999/pdf/res_2682_v2_L.pdf},
	abstract = {Dispõe sobre critérios de classificação das 
operações de crédito e regras para constituição 
de provisão para créditos de liquidação
duvidosa.},
	publisher = {Banco Central do Brasil},
	author = {{Conselho Monetário Nacional}},
	date = {1999-12-21},
}

@report{banco_do_estado_do_espirito_santo_demonstracoes_2022,
	location = {Vitória},
	title = {Demonstrações Financeiras},
	url = {https://www.banestes.com.br/ri/arquivos/informacoes/demoFinanceiras/2022_2S_demonFinanceiras.pdf},
	number = {2022},
	institution = {Banco do Estado do Espírito Santo},
	type = {Demonstrativo do resultado do exercício},
	author = {{Banco do Estado do Espírito Santo}},
	urldate = {2023-06-04},
	date = {2022},
	file = {2022_2S_demonFinanceiras.pdf:C\:\\Users\\alber\\Zotero\\storage\\8QCMXUJI\\2022_2S_demonFinanceiras.pdf:application/pdf},
}

@article{zou_regularization_2005,
	title = {Regularization and variable selection via the elastic net},
	volume = {67},
	issn = {1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00503.x},
	doi = {10.1111/j.1467-9868.2005.00503.x},
	abstract = {Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called {LARS}-{EN} is proposed for computing elastic net regularization paths efficiently, much like algorithm {LARS} does for the lasso.},
	pages = {301--320},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Zou, Hui and Hastie, Trevor},
	urldate = {2023-06-05},
	date = {2005},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2005.00503.x},
	keywords = {Grouping effect, {LARS} algorithm, Lasso, p≫n problem, Penalization, Variable selection},
	file = {Snapshot:C\:\\Users\\alber\\Zotero\\storage\\3DD6FDPD\\j.1467-9868.2005.00503.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\IDLMDRLX\\Zou e Hastie - 2005 - Regularization and variable selection via the elas.pdf:application/pdf},
}

@article{bischl_resampling_2012,
	title = {Resampling Methods for Meta-Model Validation with Recommendations for Evolutionary Computation},
	volume = {20},
	issn = {1063-6560},
	doi = {10.1162/EVCO_a_00069},
	abstract = {Meta-modeling has become a crucial tool in solving expensive optimization problems. Much of the work in the past has focused on finding a good regression method to model the fitness function. Examples include classical linear regression, splines, neural networks, Kriging and support vector regression. This paper specifically draws attention to the fact that assessing model accuracy is a crucial aspect in the meta-modeling framework. Resampling strategies such as cross-validation, subsampling, bootstrapping, and nested resampling are prominent methods for model validation and are systematically discussed with respect to possible pitfalls, shortcomings, and specific features. A survey of meta-modeling techniques within evolutionary optimization is provided. In addition, practical examples illustrating some of the pitfalls associated with model selection and performance assessment are presented. Finally, recommendations are given for choosing a model validation technique for a particular setting.},
	pages = {249--275},
	number = {2},
	journaltitle = {Evolutionary Computation},
	author = {Bischl, B. and Mersmann, O. and Trautmann, H. and Weihs, C.},
	date = {2012-06},
	note = {Conference Name: Evolutionary Computation},
	keywords = {evolutionary computation, evolutionary optimization, meta-models, model validation, regression, Resampling},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\alber\\Zotero\\storage\\IEX488WG\\6794050.html:text/html;Texto completo:C\:\\Users\\alber\\Zotero\\storage\\75FUR9NE\\Bischl et al. - 2012 - Resampling Methods for Meta-Model Validation with .pdf:application/pdf},
}

@article{gross_disaggregation_1990,
	title = {Disaggregation methods to expedite product line forecasting},
	volume = {9},
	rights = {Copyright © 1990 John Wiley \& Sons, Ltd.},
	issn = {1099-131X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980090304},
	doi = {10.1002/for.3980090304},
	abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable.},
	pages = {233--254},
	number = {3},
	journaltitle = {Journal of Forecasting},
	author = {Gross, Charles W. and Sohl, Jeffrey E.},
	urldate = {2023-06-18},
	date = {1990},
	langid = {english},
	keywords = {Forecasting, Composite root mean square error differential, Disaggregational methods, Product line, Time series analysis},
	file = {Texto completo:C\:\\Users\\alber\\Zotero\\storage\\7UKW7BC2\\Gross e Sohl - 1990 - Disaggregation methods to expedite product line fo.pdf:application/pdf},
}

@article{wickramasuriya_optimal_2019,
	title = {Optimal Forecast Reconciliation for Hierarchical and Grouped Time Series Through Trace Minimization},
	volume = {114},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1448825},
	doi = {10.1080/01621459.2018.1448825},
	pages = {804--819},
	number = {526},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {Wickramasuriya, Shanika L. and Athanasopoulos, George and Hyndman, Rob J.},
	urldate = {2023-06-18},
	date = {2019-04-03},
	langid = {english},
	file = {Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\SBQ6CDQC\\Wickramasuriya et al. - 2019 - Optimal Forecast Reconciliation for Hierarchical a.pdf:application/pdf},
}

@article{dahis_data_2022,
	title = {Data Basis (Base Dos Dados): Universalizing Access to High-Quality Data},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4157813},
	doi = {10.2139/ssrn.4157813},
	shorttitle = {Data Basis (Base Dos Dados)},
	journaltitle = {{SSRN} Electronic Journal},
	shortjournal = {{SSRN} Journal},
	author = {Dahis, Ricardo and Carabetta, João and Scovino, Fernanda and Israel, Frederico and Oliveira, Diego},
	urldate = {2023-06-18},
	date = {2022},
	langid = {english},
}

@article{athanasopoulos_forecast_2023,
	title = {Forecast reconciliation: A review},
	abstract = {Collections of time series that are formed via aggregation are prevalent in many fields. These are commonly referred to as hierarchical time series and may be constructed cross-sectionally across different variables, temporally by aggregating a single series at different frequencies, or may even be generalised beyond aggregation as time series that respect linear constraints. When forecasting such time series, a desirable condition is for forecasts to be coherent, that is to respect the constraints. The past decades have seen substantial growth in this field with the development of reconciliation methods that not only ensure coherent forecasts but can also improve forecast accuracy. This paper serves as both an encyclopaedic review of forecast reconciliation and an entry point for researchers and practitioners dealing with hierarchical time series. The scope of the article includes perspectives on forecast reconciliation from machine learning, Bayesian statistics and probabilistic forecasting as well as applications in economics, energy, tourism, retail demand and demography.},
	author = {Athanasopoulos, George and Hyndman, Rob J and Kourentzes, Nikolaos and Panagiotelis, Anastasios},
	date = {2023},
	langid = {english},
	file = {Athanasopoulos et al. - 2023 - Forecast reconciliation A review.pdf:C\:\\Users\\alber\\Zotero\\storage\\LFE7V4T5\\Athanasopoulos et al. - 2023 - Forecast reconciliation A review.pdf:application/pdf},
}

@misc{bischl_hyperparameter_2021,
	title = {Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges},
	url = {http://arxiv.org/abs/2107.05847},
	doi = {10.48550/arXiv.2107.05847},
	shorttitle = {Hyperparameter Optimization},
	abstract = {Most machine learning algorithms are configured by one or several hyperparameters that must be carefully chosen and often considerably impact performance. To avoid a time consuming and unreproducible manual trial-and-error process to find well-performing hyperparameter configurations, various automatic hyperparameter optimization ({HPO}) methods, e.g., based on resampling error estimation for supervised machine learning, can be employed. After introducing {HPO} from a general perspective, this paper reviews important {HPO} methods such as grid or random search, evolutionary algorithms, Bayesian optimization, Hyperband and racing. It gives practical recommendations regarding important choices to be made when conducting {HPO}, including the {HPO} algorithms themselves, performance evaluation, how to combine {HPO} with {ML} pipelines, runtime improvements, and parallelization. This work is accompanied by an appendix that contains information on specific software packages in R and Python, as well as information and recommended hyperparameter search spaces for specific learning algorithms. We also provide notebooks that demonstrate concepts from this work as supplementary files.},
	number = {{arXiv}:2107.05847},
	publisher = {{arXiv}},
	author = {Bischl, Bernd and Binder, Martin and Lang, Michel and Pielok, Tobias and Richter, Jakob and Coors, Stefan and Thomas, Janek and Ullmann, Theresa and Becker, Marc and Boulesteix, Anne-Laure and Deng, Difan and Lindauer, Marius},
	urldate = {2023-09-04},
	date = {2021-11-24},
	eprinttype = {arxiv},
	eprint = {2107.05847 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\alber\\Zotero\\storage\\NQ2PJ3EE\\Bischl et al. - 2021 - Hyperparameter Optimization Foundations, Algorith.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alber\\Zotero\\storage\\VRPZ85ID\\2107.html:text/html},
}

@article{hyndman_state_2002,
	title = {A state space framework for automatic forecasting using exponential smoothing methods},
	volume = {18},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207001001108},
	doi = {10.1016/S0169-2070(01)00110-8},
	abstract = {We provide a new approach to automatic forecasting based on an extended range of exponential smoothing methods. Each method in our taxonomy of exponential smoothing methods provides forecasts that are equivalent to forecasts from a state space model. This equivalence allows: (1) easy calculation of the likelihood, the {AIC} and other model selection criteria; (2) computation of prediction intervals for each method; and (3) random simulation from the underlying state space model. We demonstrate the methods by applying them to the data from the M-competition and the M3-competition. The method provides forecast accuracy comparable to the best methods in the competitions; it is particularly good for short forecast horizons with seasonal data.},
	pages = {439--454},
	number = {3},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Hyndman, Rob J and Koehler, Anne B and Snyder, Ralph D and Grose, Simone},
	urldate = {2023-11-26},
	date = {2002-07-01},
	keywords = {Exponential smoothing, Automatic forecasting, Prediction intervals, State space models},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\97VEA3W2\\S0169207001001108.html:text/html;Versão submetida:C\:\\Users\\alber\\Zotero\\storage\\NV3HRL7W\\Hyndman et al. - 2002 - A state space framework for automatic forecasting .pdf:application/pdf},
}

@misc{abolghasemi_model_2020,
	title = {Model selection in reconciling hierarchical time series},
	url = {http://arxiv.org/abs/2010.10742},
	doi = {10.48550/arXiv.2010.10742},
	abstract = {Model selection has been proven an effective strategy for improving accuracy in time series forecasting applications. However, when dealing with hierarchical time series, apart from selecting the most appropriate forecasting model, forecasters have also to select a suitable method for reconciling the base forecasts produced for each series to make sure they are coherent. Although some hierarchical forecasting methods like minimum trace are strongly supported both theoretically and empirically for reconciling the base forecasts, there are still circumstances under which they might not produce the most accurate results, being outperformed by other methods. In this paper we propose an approach for dynamically selecting the most appropriate hierarchical forecasting method and succeeding better forecasting accuracy along with coherence. The approach, to be called conditional hierarchical forecasting, is based on Machine Learning classification methods and uses time series features as leading indicators for performing the selection for each hierarchy examined considering a variety of alternatives. Our results suggest that conditional hierarchical forecasting leads to significantly more accurate forecasts than standard approaches, especially at lower hierarchical levels.},
	number = {{arXiv}:2010.10742},
	publisher = {{arXiv}},
	author = {Abolghasemi, Mahdi and Hyndman, Rob J. and Spiliotis, Evangelos and Bergmeir, Christoph},
	urldate = {2023-11-28},
	date = {2020-10-29},
	eprinttype = {arxiv},
	eprint = {2010.10742 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\alber\\Zotero\\storage\\QM8CLNRK\\Abolghasemi et al. - 2020 - Model selection in reconciling hierarchical time s.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alber\\Zotero\\storage\\ZBQVEI5N\\2010.html:text/html},
}

@inproceedings{chen_xgboost_2016,
	location = {New York, {NY}, {USA}},
	title = {{XGBoost}: A Scalable Tree Boosting System},
	isbn = {978-1-4503-4232-2},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	series = {{KDD} '16},
	shorttitle = {{XGBoost}},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called {XGBoost}, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, {XGBoost} scales beyond billions of examples using far fewer resources than existing systems.},
	pages = {785--794},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	publisher = {Association for Computing Machinery},
	author = {Chen, Tianqi and Guestrin, Carlos},
	urldate = {2024-01-23},
	date = {2016-08-13},
	keywords = {large-scale machine learning},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\LXG5VJ9V\\Chen e Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf:application/pdf},
}

@inproceedings{ke_lightgbm_2017,
	title = {{LightGBM}: A Highly Efficient Gradient Boosting Decision Tree},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html},
	shorttitle = {{LightGBM}},
	abstract = {Gradient Boosting Decision Tree ({GBDT}) is a popular machine learning algorithm, and has quite a few effective implementations such as {XGBoost} and {pGBRT}. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: {\textbackslash}emph\{Gradient-based One-Side Sampling\} ({GOSS}) and {\textbackslash}emph\{Exclusive Feature Bundling\} ({EFB}). With {GOSS}, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, {GOSS} can obtain quite accurate estimation of the information gain with a much smaller data size. With {EFB}, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is {NP}-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new {GBDT} implementation with {GOSS} and {EFB} {\textbackslash}emph\{{LightGBM}\}. Our experiments on multiple public datasets show that, {LightGBM} speeds up the training process of conventional {GBDT} by up to over 20 times while achieving almost the same accuracy.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
	urldate = {2024-01-23},
	date = {2017},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\JUVAPP49\\Ke et al. - 2017 - LightGBM A Highly Efficient Gradient Boosting Dec.pdf:application/pdf},
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
	pages = {273--297},
	number = {3},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	urldate = {2024-01-23},
	date = {1995-09-01},
	langid = {english},
	keywords = {efficient learning algorithms, neural networks, pattern recognition, polynomial classifiers, radial basis function classifiers},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\T893X5HL\\Cortes e Vapnik - 1995 - Support-vector networks.pdf:application/pdf},
}

@thesis{wickramasuriya_optimal_2017,
	title = {Optimal forecasts for hierarchical and grouped time series},
	url = {https://bridges.monash.edu/articles/thesis/Optimal_forecasts_for_hierarchical_and_grouped_time_series/5032136/1},
	abstract = {Large collections of time series often have aggregation constraints due to product or geographical groupings. When the time series disaggregation is unique we refer to it as a hierarchical structure whereas when it involves different paths of disaggregation we refer to it as a grouped structure. In both of these structures, forecasts for the most disaggregated series are usually required to add-up exactly to the forecasts of the aggregated series, a constraint known as aggregation consistency. Common approaches to obtaining a set of aggregate-consistent forecasts include the "bottom-up'', "top-down'' and "middle-out'' approaches. The bottom-up approach forecasts all series at the most disaggregated level and sums the forecasts to form the forecasts for higher levels. In contrast, the top-down approach forecasts the most aggregated series and distributes these forecasts based on some proportions to form the forecasts for the disaggregated series. The middle-out approach is a combination of both bottom-up and top-down approaches. Considering the drawbacks of these approaches, Hyndman, Ahmed, Athanasopoulos, and Shang (2011) proposed forecasting all disaggregated and aggregated series independently, and then reconciling the forecasts so they become aggregate consistent. Their approach is based on a generalized least squares estimator which required an estimate of the covariance matrix of the reconciliation errors that arise due to aggregate inconsistency. In this thesis I show that this covariance matrix is impossible to estimate in practice due to identifiability conditions. To overcome this issue, I propose a new forecast reconciliation approach that minimizes the mean squared error of aggregate-consistent forecasts across the entire collection of time series under the assumption of unbiasedness. The minimization problem has a closed form solution similar to that of Hyndman et al. (2011), except that the required covariance matrix is estimable leading to a feasible solution. I make this solution scalable by providing a computationally less demanding alternative representation. I refer to this approach as {MinT}. I evaluate the performance of {MinT} compared to alternative approaches in the literature using a series of simulation designs that take into account various features of the collection of time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that {MinT} performs well with both simulated and real data. Many of the applications encountered in practice have fewer observations per series than the number of series in the structure. In such situations, the sample variance covariance matrix is known to perform poorly which makes the estimation of the covariance matrix challenging and requires the use of special strategies. I mainly focused on estimators that belong to the Stein-type shrinkage, sparse, and low rank + sparse classes. For applications with a hierarchical structure, it is reasonable to assume that the covariance matrix is a representation of some lower dimension; for example, a block diagonal structure where the series with the same parental node tend to behave more similarly than the series that are less closely related. Hence, I consider modifications for some of these estimators to incorporate prior knowledge about important relationships resulting from the aggregation constraints. In addition, I explore several possibilities of reducing the computational burden of low rank + sparse type of estimators. I evaluate the performances of these competing estimators using a series of simulation designs and several empirical applications using Australian domestic tourism data. The results indicate that most of the covariance estimators contribute to substantially improving the forecast accuracy of {MinT}. In addition, I observe that prior knowledge of the correlation structure does not play a key role in improving the forecast accuracy. One of the estimators that belongs to low rank + sparse category tends to behave unexpectedly in both simulation and empirical evaluations. Through a case study I identify the causes and propose remedies for obtaining an estimator that produces consistently better performance. {MinT} and its variants can result in negative values for the reconciled forecasts even when the original set of forecasts are non-negative. This should be avoided in certain applications that are inherently non-negative in nature, especially when the forecasts are used for decisions or policy implementation processes. Hence, {MinT} is reformulated as a least squares minimization problem with non-negativity constraints. Considering the dimension and sparsity of the matrices involved and the alternative representation of {MinT}, this problem is solved using three algorithms: block principal pivoting, projected conjugate gradient and scaled gradient projection. I compare the performances of these algorithms using a series of simulations and an empirical application. The results reveal that the block principal pivoting algorithm outperforms the rest where a structure with nearly six hundred thousand series can be reconciled in less than one minute using a standard desktop computer. In addition, it is observed that the gains or losses in forecast accuracy due to non-negativity constraints are negligible},
	institution = {Monash University},
	type = {thesis},
	author = {Wickramasuriya, Shanika L.},
	urldate = {2024-03-09},
	date = {2017-05-23},
	langid = {english},
	doi = {10.4225/03/5923c4e094308},
	file = {Full Text PDF:C\:\\Users\\alber\\Zotero\\storage\\JLG8TL2G\\Wickramasuriya - 2017 - Optimal forecasts for hierarchical and grouped tim.pdf:application/pdf},
}

@book{universidade_federal_do_espirito_santo_-_biblioteca_central_normalizacao_2015,
	title = {Normalização e apresentação de trabalhos científicos e acadêmicos},
	isbn = {978-85-7772-274-7},
	publisher = {Edufes},
	author = {{Universidade Federal do Espírito Santo - Biblioteca Central}},
	date = {2015-02-24},
	langid = {portuguese},
	keywords = {Biblioteconomia e ciência da informação},
	file = {2015 - Normalização e apresentação de trabalhos científic.pdf:C\:\\Users\\alber\\Zotero\\storage\\LG2VYL74\\2015 - Normalização e apresentação de trabalhos científic.pdf:application/pdf},
}

@article{in_simple_2022,
	title = {Simple averaging of direct and recursive forecasts via partial pooling using machine learning},
	volume = {38},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001813},
	doi = {10.1016/j.ijforecast.2021.11.007},
	series = {Special Issue: M5 competition},
	abstract = {This article introduces the winning method at the M5 Accuracy competition. The presented method takes a simple manner of averaging the results of multiple base forecasting models that have been constructed via partial pooling of multi-level data. All base forecasting models of adopting direct or recursive multi-step forecasting methods are trained by the machine learning technique, {LightGBM}, from three different levels of data pools. At the competition, the simple averaging of the multiple direct and recursive forecasting models, called {DRFAM}, obtained the complementary effects between direct and recursive multi-step forecasting of the multi-level product sales to improve the accuracy and the robustness.},
	pages = {1386--1399},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {In, {YeonJun} and Jung, Jae-Yoon},
	urldate = {2024-03-15},
	date = {2022-10-01},
	keywords = {Machine learning, Direct and recursive multi-step forecasting, Forecast averaging, {LightGBM}, Multi-level data},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\D3F7RWAJ\\S0169207021001813.html:text/html},
}

@article{makridakis_m5_2022,
	title = {M5 accuracy competition: Results, findings, and conclusions},
	volume = {38},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001874},
	doi = {10.1016/j.ijforecast.2021.11.013},
	series = {Special Issue: M5 competition},
	shorttitle = {M5 accuracy competition},
	abstract = {In this study, we present the results of the M5 “Accuracy” competition, which was the first of two parallel challenges in the latest M competition with the aim of advancing the theory and practice of forecasting. The main objective in the M5 “Accuracy” competition was to accurately predict 42,840 time series representing the hierarchical unit sales for the largest retail company in the world by revenue, Walmart. The competition required the submission of 30,490 point forecasts for the lowest cross-sectional aggregation level of the data, which could then be summed up accordingly to estimate forecasts for the remaining upward levels. We provide details of the implementation of the M5 “Accuracy” challenge, as well as the results and best performing methods, and summarize the major findings and conclusions. Finally, we discuss the implications of these findings and suggest directions for future research.},
	pages = {1346--1364},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
	urldate = {2024-03-15},
	date = {2022-10-01},
	keywords = {Accuracy, Forecasting competitions, M competitions, Machine learning, Retail sales forecasting, Time series},
	file = {ScienceDirect Snapshot:C\:\\Users\\alber\\Zotero\\storage\\U6XGUK9W\\S0169207021001874.html:text/html},
}

@article{shiratori_prediction_2020,
	title = {Prediction of hierarchical time series using structured regularization and its application to artificial neural networks},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242099},
	doi = {10.1371/journal.pone.0242099},
	abstract = {This paper discusses the prediction of hierarchical time series, where each upper-level time series is calculated by summing appropriate lower-level time series. Forecasts for such hierarchical time series should be coherent, meaning that the forecast for an upper-level time series equals the sum of forecasts for corresponding lower-level time series. Previous methods for making coherent forecasts consist of two phases: first computing base (incoherent) forecasts and then reconciling those forecasts based on their inherent hierarchical structure. To improve time series predictions, we propose a structured regularization method for completing both phases simultaneously. The proposed method is based on a prediction model for bottom-level time series and uses a structured regularization term to incorporate upper-level forecasts into the prediction model. We also develop a backpropagation algorithm specialized for applying our method to artificial neural networks for time series prediction. Experimental results using synthetic and real-world datasets demonstrate that our method is comparable in terms of prediction accuracy and computational efficiency to other methods for time series prediction.},
	pages = {e0242099},
	number = {11},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Shiratori, Tomokaze and Kobayashi, Ken and Takano, Yuichi},
	urldate = {2024-03-18},
	date = {2020-11-12},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Algorithms, Artificial neural networks, Cognitive science, Computing methods, Covariance, Forecasting, Linear regression analysis, Neural networks},
	file = {Full Text PDF:C\:\\Users\\Alberson\\Zotero\\storage\\I4J5HZ75\\Shiratori et al. - 2020 - Prediction of hierarchical time series using struc.pdf:application/pdf},
}

@misc{meyer__aut_e1071_2023,
	title = {e1071: {Misc} {Functions} of the {Department} of {Statistics}, {Probability} {Theory} {Group} ({Formerly}: {E1071}), {TU} {Wien}},
	copyright = {GPL-2 {\textbar} GPL-3},
	shorttitle = {e1071},
	url = {https://cran.r-project.org/web/packages/e1071/index.html},
	abstract = {Functions for latent class analysis, short time Fourier transform, fuzzy clustering, support vector machines, shortest path computation, bagged clustering, naive Bayes classifier, generalized k-nearest neighbour ...},
	urldate = {2024-03-22},
	author = {Meyer  [aut, David and cre and Dimitriadou, Evgenia and Hornik, Kurt and Weingessel, Andreas and Leisch, Friedrich and C++-code), Chih-Chung Chang (libsvm and C++-code), Chih-Chen Lin (libsvm},
	month = dec,
	year = {2023},
	keywords = {Cluster, Distributions, Environmetrics, MachineLearning, Psychometrics},
}
