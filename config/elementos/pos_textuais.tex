% elementos pós-textuais 
\postextual

% apêndice 
\begin{apendicesenv}
\partapendices

% Apêndice A
\chapter{DEMONSTRAÇÕES} \label{apendice_a}

% proposição 1
\begin{proposition}[condição de ausência de viés em $\mathbfit{\tilde{y}}$]
  \label{proposicao1}

  Se as previsões reconciliadas são não viesadas, então $\mathbfit{SGS=S}$, ou seja, $\mathbfit{G}$ é inversa generalizada de $\mathbfit{S}$.

\end{proposition}

\begin{proof}
  \begin{equation} \label{eq:ap1}
    \mathbfit{\tilde{y}}_{t+h|t} = \mathbfit{SG\hat{y}}_{t+h|t} 
  \end{equation}

  Se $\mathbfit{\hat{y}}_{t+h|t}$ é não viesado, então 

  \begin{equation} \label{eq:ap2}
      \mathbb{E}[\mathbfit{\hat{y}}_{t+h|t}] = \mathbb{E}[\mathbfit{y}_{t+h|t}] = \mathbfit{Sb}_t
  \end{equation}

  Da mesma forma, se espera-se que as previsões reconciliadas não sejam viesadas,
  \begin{equation} \label{eq:ap3}
      \mathbb{E}[\mathbfit{\tilde{y}}_{t+h|t}] = \mathbb{E}[\mathbfit{y}_{t+h|t}] = \mathbfit{Sb}_t
  \end{equation}

  Substituindo \eqref{eq:ap2} em \eqref{eq:ap1}, temos

  \begin{equation} \label{eq:ap4}
      \mathbfit{\tilde{y}}_{t+h|t} = \mathbfit{SGSb}_t 
  \end{equation}

  Logo, para manter a igualdade entre \eqref{eq:ap1} e \eqref{eq:ap4}, $\mathbfit{SGS=S}$

\end{proof}

% proposição 2
\begin{proposition}
  \label{proposicao2}

  $\mathbfit{\tilde{e}}_t = \mathbfit{SG\hat{e}}_t$.

\end{proposition}

\begin{proof}
  \begin{equation} \label{eq:apa22}
    \mathbfit{\tilde{e}}_{t+h|t} = \mathbfit{y}_{t+h} - \mathbfit{\tilde{y}}_{t +h|t}
  \end{equation}

  Substituindo \eqref{eq:ap1} em \eqref{eq:apa22},

  \begin{align} \label{eq:apa23}
    \mathbfit{\tilde{e}}_{t+h|t} &= \mathbfit{y}_{t+h} - \mathbfit{SG\hat{y}}_{t+h|t}
  \end{align}

  Lembrando que, por definição, $\mathbfit{y}_{t+h} = \mathbfit{\hat{y}}_{t+h|t} + \mathbfit{\hat{e}}_{t+h|t}$, então

  \begin{align} \label{eq:apa24}
    \mathbfit{\tilde{e}}_{t+h|t} &= \mathbfit{\hat{y}}_{t+h|t} + \mathbfit{\hat {e}}_{t+h|t} - \mathbfit{SG\hat{y}}_{t+h|t} \\
    &= \mathbfit{\hat{e}}_{t+h|t} + \mathbfit{\hat{y}}_{t+h|t}(\mathbfit{I-SG)}
  \end{align}

  Usando a definição novamente, temos que

  \begin{align}
    \mathbfit{\tilde{e}}_{t+h|t} &= \mathbfit{\hat{e}}_{t+h|t} + (\mathbfit{y}_ {t+h} - \mathbfit{\hat{e}}_{t+h|t})(\mathbfit{I-SG)} \\
    &= \mathbfit{y}_{t+h} - \mathbfit{SGy}_{t+h|t} + \mathbfit{SG\hat{e}}_{t+h| t} \\
    &=  \mathbfit{y}_{t+h}(\mathbfit{I-SG}) + \mathbfit{SG\hat{e}}_{t+h|t}  \label{eq:apa25}
  \end{align}

  Substituindo \eqref{eq-vetor_b} em \eqref{eq:apa25}, temos

  \begin{align}
    \mathbfit{\tilde{e}}_{t+h|t} &=  \mathbfit{Sb}_{t+h}(\mathbfit{I-SG}) +  \mathbfit{SG\hat{e}}_{t+h|t} \\
    &=  \mathbfit{Sb}_{t+h} - \mathbfit{Sb}_{t+h}\mathbfit{SG} + \mathbfit {SG\hat{e}}_{t+h|t}  \\
    &=  \mathbfit{Sb}_{t+h} - \mathbfit{(G'S')(b'}_{t+h}\mathbfit{S')} +   \mathbfit{SG\hat{e}}_{t+h|t}  \\
    &=  \mathbfit{Sb}_{t+h} - \mathbfit{SG}\mathbfit{Sb}_{t+h} + \mathbfit {SG\hat{e}}_{t+h|t}
  \end{align}

  Finalmente, pela \nameref{proposicao1}, temos que

  \begin{align}
    \mathbfit{\tilde{e}}_{t+h|t} &=  \mathbfit{Sb}_{t+h} - \mathbfit{Sb}_{t+h}  + \mathbfit{SG\hat{e}}_{t+h|t}  \\
    &= \mathbfit{SG\hat{e}}_{t+h|t}
  \end{align}
\end{proof}

% proposição 3
\begin{proposition}
  \label{proposicao3}

  $\text{Var}[\mathbfit{\tilde{e}}_t] = \mathbfit{SG\hat{W}G'S'}$.

\end{proposition}

\begin{proof}
  Por \ref{proposicao2}, temos que

  \begin{align}
    \text{Var}[\mathbfit{\tilde{e}}] &= \mathbb{E}[\mathbfit{(SG\hat{e})(SG\hat {e})'}] \\
    &= \mathbb{E}[\mathbfit{SG\hat{e}\hat{e}'G'S'}] \\
    &= \mathbfit{SG\hat{W}G'S'}
  \end{align}

  Em que $\mathbfit{\hat{W}}$ é a matriz de variância-covariância dos erros de  previsão base.
\end{proof}

% proposição 4
\begin{proposition}
  \label{proposicao4}

  $\mathbfit{\hat{W}}$ é posto incompleto.

\end{proposition}

\begin{proof}
  Pela propriedade do vínculo do posto do produto de matrizes, ou seja, $pos(\mathbfit{AB}) \leq min(pos(\mathbfit{A}), pos(\mathbfit{B}))$, temos que
  
  \begin{equation}
    pos(\mathbfit{SG\hat{e}}_{t+h|t}) \leq min(pos(\mathbfit{S}), pos(\mathbfit{G}), pos(\mathbfit{\hat{e}}_{t+h|t})) \label{eq:ap_a_4_1}
  \end{equation}

  Como $\mathbfit{S}$ é a representação matricial de uma estrutura hierárquica, em que os nós pais totalizam os nós filhos, $\mathbfit{S}$ apresenta, por hipótese, dependência linear e, consequentemente, posto incompleto.

  Pela equação \eqref{eq:ap_a_4_1}, segue que $\mathbfit{\tilde{e}}$ é posto incompleto. Da mesma forma, $pos(\mathbfit{\tilde{e}\tilde{e}'}) \leq min(pos(\mathbfit{\tilde{e}}), pos(\mathbfit{\tilde{e}'}))$. Portanto, $\mathbfit{\hat{W}}$ é posto incompleto.
\end{proof}

\end{apendicesenv}

% anexos 
\begin{anexosenv}
\partanexos

\chapter{CONJUNTO DE HIPERPARÂMETROS} \label{anexo_a}

\begin{table}

  \caption{\label{tab:tbl-hip-xgboost}Intervalos de hiperparâmetros para \{xgboost\}}
  \centering
  \begin{tabular}[t]{llll}
  \toprule
  Hiperparâmetro & Descrição & Intervalo & Trafo\\
  \midrule
  \cellcolor{gray!6}{nrounds} & \cellcolor{gray!6}{Número de iterações} & \cellcolor{gray!6}{$[1, 5000]$} & \cellcolor{gray!6}{NULL}\\
  eta & Taxa de aprendizado & $[-4, 0]$ & $10^x$\\
  \cellcolor{gray!6}{max\_depth} & \cellcolor{gray!6}{Profundidade máxima} & \cellcolor{gray!6}{$[1, 20]$} & \cellcolor{gray!6}{NULL}\\
  subsample & Subamostra & $[0.1, 1]$ & NULL\\
  \cellcolor{gray!6}{colsample\_bytree} & \cellcolor{gray!6}{Subamostra de colunas para uma árvore} & \cellcolor{gray!6}{$[0.1, 1]$} & \cellcolor{gray!6}{NULL}\\
  \addlinespace
  colsample\_bylevel & Subamostra de colunas por nível de profundidade & $[0.1, 1]$ & NULL\\
  \cellcolor{gray!6}{lambda} & \cellcolor{gray!6}{Regularização L2} & \cellcolor{gray!6}{$[-10, 10]$} & \cellcolor{gray!6}{$2^x$}\\
  alpha & Regularização L1 & $[-10, 10]$ & $2^x$\\
  \bottomrule
  \end{tabular}
\end{table}

\begin{table}

  \caption{\label{tab:tbl-hip-lightgbm}Intervalos de hiperparâmetros para \{lightgbm\}}
  \centering
  \begin{tabular}[t]{llll}
  \toprule
  Hiperparâmetro & Descrição & Intervalo & Trafo\\
  \midrule
  \cellcolor{gray!6}{num\_iterations} & \cellcolor{gray!6}{Número de iterações} & \cellcolor{gray!6}{$[1, 1000]$} & \cellcolor{gray!6}{NULL}\\
  boosting & Algoritmo de boosting & \{gbdt, dart, goss\} & NULL\\
  \cellcolor{gray!6}{learning\_rate} & \cellcolor{gray!6}{Taxa de aprendizado} & \cellcolor{gray!6}{$[-4, 0]$} & \cellcolor{gray!6}{$10^x$}\\
  num\_leaves & Número de folhas & $[2, 20]$ & NULL\\
  \cellcolor{gray!6}{lambda\_l1} & \cellcolor{gray!6}{Regularização L1} & \cellcolor{gray!6}{$[-12, 12]$} & \cellcolor{gray!6}{$2^x$}\\
  \addlinespace
  lambda\_l2 & Regularização L2 & $[-12, 12]$ & $2^x$\\
  \cellcolor{gray!6}{feature\_fraction} & \cellcolor{gray!6}{Subamostra de colunas} & \cellcolor{gray!6}{$[0.1, 1]$} & \cellcolor{gray!6}{NULL}\\
  bagging\_fraction & Subamostra de linhas & $[0.1, 1]$ & NULL\\
  \cellcolor{gray!6}{bagging\_freq} & \cellcolor{gray!6}{Frequência de amostragem} & \cellcolor{gray!6}{$[1, 10]$} & \cellcolor{gray!6}{NULL}\\
  \bottomrule
  \end{tabular}
\end{table}

\begin{table}

  \caption{\label{tab:tbl-hip-ranger}Intervalos de hiperparâmetros para \{ranger\}}
  \centering
  \resizebox{\linewidth}{!}{
  \begin{tabular}[t]{llll}
  \toprule
  Hiperparâmetro & Descrição & Intervalo & Trafo\\
  \midrule
  \cellcolor{gray!6}{min.node.size} & \cellcolor{gray!6}{Número mínimo de observações em um nó terminal} & \cellcolor{gray!6}{$[1,7]$} & \cellcolor{gray!6}{$2^x$}\\
  mtry & Número de variáveis candidatas para split & $[1,)$ & NULL\\
  \cellcolor{gray!6}{replace} & \cellcolor{gray!6}{Amostragem com reposição} & \cellcolor{gray!6}{\{TRUE, FALSE\}} & \cellcolor{gray!6}{NULL}\\
  sample.fraction & Fração de observações a serem amostradas & $[0.1, 1]$ & NULL\\
  \cellcolor{gray!6}{num.trees} & \cellcolor{gray!6}{Número de árvores} & \cellcolor{gray!6}{$[1, 2000]$} & \cellcolor{gray!6}{NULL}\\
  \bottomrule
  \end{tabular}}
\end{table}

\begin{table}

  \caption{\label{tab:tbl-hip-svm}Intervalos de hiperparâmetros para \{e1071\} (svm)
  }
  \centering
  \begin{tabular}[t]{llll}
  \toprule
  Hiperparâmetro & Descrição & Intervalo & Trafo\\
  \midrule
  \cellcolor{gray!6}{cost} & \cellcolor{gray!6}{Custo de $\xi$} & \cellcolor{gray!6}{$[0, 1]$} & \cellcolor{gray!6}{$2^x$}\\
  kernel & Kernel & \{linear, polynomial, radial, sigmoid\} & NULL\\
  \cellcolor{gray!6}{degree} & \cellcolor{gray!6}{Grau do polinômio} & \cellcolor{gray!6}{$[1, 5]$} & \cellcolor{gray!6}{NULL}\\
  gamma & Influência amostral & $[-12, 12]$ & $2^x$\\
  \cellcolor{gray!6}{type} & \cellcolor{gray!6}{Tipo de SVM} & \cellcolor{gray!6}{\{eps-regression\}} & \cellcolor{gray!6}{NULL}\\
  \bottomrule
  \end{tabular}
\end{table}

\begin{table}

  \caption{\label{tab:tbl-hip-glmnet}Intervalos de hiperparâmetros para \{glmnet\}}
  \centering
  \begin{tabular}[t]{llll}
  \toprule
  Hiperparâmetro & Descrição & Intervalo & Trafo\\
  \midrule
  \cellcolor{gray!6}{alpha} & \cellcolor{gray!6}{Mix entre lasso e ridge} & \cellcolor{gray!6}{$[0, 1]$} & \cellcolor{gray!6}{NULL}\\
  lambda & Regularização & $[-12, 12]$ & $2^x$\\
  \bottomrule
  \end{tabular}
\end{table}

\end{anexosenv}

% índice remissivo 
%\phantompart
%\printindex
