---
format:
  pdf:
    include-in-header: [config/tema/preamble.tex, config/tema/customizacao.tex]
    include-before-body: config/elementos/pre_textuais.tex
    include-after-body: config/elementos/pos_textuais.tex
    documentclass: abntex2
    classoption: [12pt, twoside, openright, a4paper, chapter=TITLE, section=TITLE, brazil]
    keep-tex: true
    latex-max-runs: 4
    output-file: dissertacao.pdf
---

```{r config}
#| include = FALSE

# opções
knitr::opts_chunk$set(
  out.width = "90%"
)

# reprodutibilidade
set.seed(1)

# pacotes
pacman::p_load(
  kableExtra,
  ggplot2,
  tsibble,
  fable,
  fabletools
)

# paleta de cores Banestes
cores = list(
  azul_banestes = "#0041C4",
  verde_banestes = "#4FFF00",
  azul_medio_banestes = "#0D8CFF",
  azul_claro_banestes = "#82E3FF",
  azul_escuro_aux = "#002F7A",
  azul_medio_aux = "#0056C4",
  azul_claro_aux = "#0079DB",
  bege_aux = "#E0DB9E",
  cor_quente_aux = "#991F00",
  cinza_aux = "#CDD1D1"
)

# tema ggplot
tema = theme_classic() +
  theme(
    text = element_text(family = "serif"),
    strip.background = element_rect(fill = cores$azul_escuro_aux),
    strip.text = element_text(color = "white")
  )

# gerar bibliografia de pacotes
knitr::write_bib(
  c(
    .packages(),
    "basedosdados",
    "mlr3",
    "xgboost",
    "e1071",
    "ranger",
    "lightgbm",
    "glmnet"
  ),
  file = "config/elementos/packages.bib"
)

# dados
estban = readRDS("data/estban/estban.rds")

# filtrando dados
estban = subset(estban,
  select = c(
    ref,
    nome_mesorregiao,
    nome_microrregiao,
    nome,
    cnpj_agencia,
    verbete,
    saldo
  )
) |>
  tsibble::filter_index(~"2022-12-31") |>
  (\(x) x[order(
    x$ref,
    x$nome_mesorregiao,
    x$nome_microrregiao,
    x$nome,
    x$cnpj_agencia,
    x$verbete
  ), ])()
```

# INTRODUÇÃO

## Previsão de saldos de crédito de instituições financeiras

Embora no séc. XX ainda houvesse espaço para uma gestão guiada apenas por instinto [@wallander_budgeting_1999], atualmente é impensável um banco não realizar previsões de seus resultados e comunicar suas expectativas ao mercado. Nesse documento, ou *guidance*, a projeção da carteira de crédito — o total de empréstimos e financiamentos, dentre outros itens — é frequentemente a primeira informação fornecida. Juntamente com as projeções de depósitos, provisões para créditos de liquidação duvidosa, eficiência operacional, entre outros indicadores-chave, essas projeções determinam a temperatura das expectativas da instituição, e isso é essencial para os acionistas e investidores. Essas projeções precisam ser tão precisas quanto possível para que se possa calcular o risco de transacionar com a instituição financeira.

Ainda que não existam penalidades específicas para instituições financeiras que erram (por uma boa margem) em suas projeções, elas podem sofrer consequências negativas em outros aspectos, como na avaliação de seus desempenhos por parte dos investidores e clientes. Estes podem considerar as projeções equivocadas como um sinal de falta de competência ou confiança na instituição financeira, o que pode afetar negativamente a reputação e a imagem da instituição.

Além disso, nos casos em que algum grupo se sentir lesado, os bancos podem enfrentar ações judiciais se suas projeções forem consideradas enganosas ou fraudulentas. Por exemplo, se uma instituição financeira fizer projeções excessivamente otimistas para incentivar os investidores a comprar seus títulos e, posteriormente, as projeções se mostrarem incorretas, ela pode ser acusada de fraude^[Art. 3º: Divulgar informação falsa ou prejudicialmente incompleta sobre instituição financeira. Pena: Reclusão, de 2 (dois) a 6 (seis) anos, e multa. Art. 4º: Gerir fraudulentamente instituição financeira. Pena: Reclusão, de 3 (três) a 12 (doze) anos, e multa [@brasil_lei_1986].] ou, ao menos, gestão temerária^[Art. 4º, parágrafo único: Se a gestão é temerária: Pena: Reclusão, de 2 (dois) a 8 (oito) anos, e multa [@brasil_lei_1986].] — ambos caracterizados como crime contra o Sistema Financeiro Nacional.

Por isso, é importante que as instituições financeiras sejam transparentes e precisas em suas projeções, fornecendo informações confiáveis e atualizadas para seus clientes e investidores. No entanto, há também motivações estratégicas para essa atividade. @beccalli_earnings_2015 mostraram que, em uma amostra de 55 bancos europeus, a utilização de *guidance* está associada a um aumento de 15% na probabilidade do banco atingir ou superar as expectativas de mercado. Isso, por sua vez, está associado a um incremento de até 5% no retorno por ação em relação aos bancos que não alcançaram ou superaram as expectativas.

## Previsão de séries temporais hierárquicas

No que concerne a elaboração dessas previsões, os bancos, assim como em diversas outras indústrias, se enquadram em uma categoria de negócio que requerem previsões de múltiplas séries temporais correlacionadas que são resultados de agregação. Por exemplo, o total de empréstimos de uma instituição financeira corresponde ao agregado dos empréstimos de cada uma de suas agências; o total de vendas de uma rede nacional de farmácias corresponde ao agregado de vendas de suas unidades em cada estado; o total da produção de uma petrolífica multinacional corresponde ao total produzido em cada país por cada uma de suas plataformas. A essas estruturas naturais de agregação dá-se o nome de *séries temporais hierárquicas*.

Pode-se realizar previsões individualmente para todos os níveis da estrutura. No caso de uma insituição financeira, isso significa realizar previsões, por exemplo, para cada agência, para o agregado de cada região e para o agregado da instituição. Infelizmente, não há qualquer razão, exceto para métodos de previsão muito simples, para que essas previsões sejam *coerentes* (i.e. que a soma das previsões individuais seja igual à previsão do agregado). Além disso, realizar as previsões individualmente ignoraria os relacionamentos existentes entre as séries temporais na estrutura. Para fazer com que essas previsões se tornem coerentes entre si é que foram desenvolvidos os chamados métodos de *reconciliação*, sendo os mais simples o *top-down*, *bottom-up* e uma combinação das duas, a *middle-out*.

A prática usual em *budgeting*^[O orçamento é um documento no qual é definido o planejamento financeiro de um empresa, geralmente para o ano seguinte, estabelecendo metas e objetivos. Nele são projetadas as expectativas da empresa e é base de comparação para saber como os resultados estão se desviando da performance esperada.], principalmente para empresas com muitas filiais, é a *top-down*, ou seja, realizar previsões para o total e então distribuí-las para cada unidade seguindo alguma lógica proporcional. No caso dos bancos de varejo, com muitas agências espalhadas pelo território, especialmente em um país grande como o Brasil, esse método pode ser muito prático.

Esse é o caso do Banestes. Com 134 agências distribuídas pelos 78 municípios capixabas, realizar o *budgeting* para R$ 5,5 bi de faturamento^[Conforme demonstrativos publicados referentes ao exercício de 2022 [@banco_do_estado_do_espirito_santo_demonstracoes_2022].] não é uma tarefa trivial. Além de uma estrutura hierárquica de alta dimensionalidade por conta da quantidade de agências, se tratando de um banco múltiplo^[Para ser classificado como banco múltiplo, a instituição financeira deve operar com, no mínimo, duas carteiras dentre: comercial; investimento ou desenvolvimento; crédito imobiliário; de crédito, financiamento e investimento, e; arrendamento mercantil [@conselho_monetario_nacional_resolucao_1994].] que opera com diversas carteiras, as $n$ modalidades de crédito^[Crédito consignado, rural, imobiliário, pessoal, capital de giro, desconto de títulos etc.] expandem a estrutura para um total de $n \times 134$ séries temporais a serem estimadas.

Dada tal complexidade, a abordagem *top-down* se coloca como uma opção viável em termos de tempo de processamento e análise. No entanto, conforme descemos na hierarquia, menos precisa ela se torna e, além disso, as características individuais das séries temporais do menor nível hierárquicos são ignoradas.

Tomando o caminho inverso, a abordagem *bottom-up* consiste em realizar previsões para cada série temporal individualmente e, então, agregá-las para obter a previsão para o total. Essa abordagem pode ser mais precisa, pois leva em consideração as características individuais de cada série temporal do nível mais desagregado. No entanto, ela é mais custosa em termos de tempo de processamento e análise. Nesse sentido, cabe ao analista avaliar o *trade-off* entre os ganhos de precisão percebidos com a geração de previsões individuais e a economia de tempo e processamento em realizar o contrário [@gross_disaggregation_1990].

Além disso, ambas são abordagens de nível único, isto é, são realizadas as previsões para um único nível e então os demais níveis são obtidos agregando ou desagregando. O problema com esses tipos de abordagem é que elas utilizam informação incompleta [@hyndman_forecasting_2021]. Por exemplo, suponha-se que se escolha estimar modelos para cada uma das 134 agências e agregá-las (*bottom-up*). Nesse caso, ignora-se a influência que os níveis mais agregados — aqui a carteira de crédito da região ou de todo o estado — pode ter na estimação do saldo de crédito de cada agência. Por outro lado, se escolher estimar modelos para os níveis mais agregados (*top-down*), ignora-se a informação individual de cada agência.

Uma terceira possibilidade é a *reconciliação ótima*. Ela é uma abordagem que busca resolver esse problema e consiste em realizar previsões para todos os níveis hierárquicos e, então, estimar um modelo para reescrever as previsões do nível mais desagregado como uma combinação linear de todos os elementos da hierarquia. Obtidas as novas previsões no menor nível, ela são então agregadas, gerando previsões coerentes nos níveis superiores. Dessa forma, a informação de todos os níveis é utilizada na estimação dos modelos e na geração das previsões, ao mesmo tempo em que a variância do erro de previsão é minimizado [@hyndman_optimal_2011].

Atualmente, os métodos analíticos baseados na minimização do traço (MinT) da matriz da variância-covariância dos erros, desenvolvidos em  @wickramasuriya_optimal_2019, são os mais populares na literatura da reconciliação ótima. Esses métodos divergem apenas na forma da qual se dá o relacionamento entre os diferentes elementos da hierarquia, resultando numa estimação por mínimos quadrados ordinários (MQO), mínimos quadrados ponderados (MQP) ou mínimos quadrados generalizados (MQG)^[Se os erros de previsão são descorrelacionados e homoscedásticos ao longo de toda estrutura (MQO), o que é impossível em séries temporais hierárquicas; se os erros são descorrelacionados e homoscedásticos apenas dentro do mesmo nível hierárquico (MQP estrutural); se os erros são descorrelacionados mas ponderados pela variância da série (MQP); ou se são correlacionados e variantes ao longo de toda a estrutura (MQG, também chamados de *MinT Sample* e *MinT Shrink*).].

Entretanto, tais métodos são sujeitos a uma série de restrições, como as do modelo clássico de regressão linear (MCRL), e têm sua capacidade preditiva reduzida quando suas hipóteses são violadas. Além disso, esses métodos requerem que *toda* a informação seja utilizada, mesmo aquelas que eventualmente não sejam relevantes para aquela previsão. Nesse sentido, métodos de *machine learning* são mais gerais, no sentido de permitir parâmetros não lineares e poderem aproximar virtualmente qualquer função, além de incluírem parâmetros de regularização, de forma que não necessariamente utilizam toda a informação disponível. Espera-se, portanto, que esses métodos alcancem melhor performance no problema da reconciliação ótima, justificando a pesquisa e atenção ao tema. Nesse sentido, @spiliotis_hierarchical_2021 propuseram uma metodologia para reconciliação ótima de séries temporais hierárquicas utilizando métodos de *machine learning*, especificamente o *gradient boosting* e floresta aleatória, obtendo resultados superiores aos métodos analíticos.

Tomando como ponto de partida a metodologia proposta por @spiliotis_hierarchical_2021, este trabalho estende seu uso para outros métodos de *machine learning* na tarefa de reconciliação ótima, especificamente os métodos de regressão regularizada lasso, ridge e *elastic net*, e *support vector machine* (SVM), além de outra implementação de *gradient boosting*. Paralelamente, propõe e avalia estratégias alternativas na metodologia de @spiliotis_hierarchical_2021, verificando se sua performance se mantêm superior à dos métodos analíticos em um contexto de séries temporais financeiras de alta dimensionalidade.

Esta dissertação está organizada da seguinte forma: no Capítulo 2, é realizada uma breve revisão de literatura sobre o tema. No Capítulo 3, é introduzida a formalização algébrica necessária para a compreensão dos métodos de reconciliação. No Capítulo 4, são apresentados os dados e a metodologia do experimento. No Capítulo 5, os resultados são apresentados e discutidos.

# REVISÃO DE LITERATURA

## Previsão de saldos de crédito de instituições financeiras

A nível macroeconômico, a previsão do agregado de crédito das instituições financeiras é uma preocupação de bancos centrais ao redor do mundo. No Brasil, @bader_modelo_2014 aprimoram o método FAVAR (*Factor Augmented Vector Autoregression*) com uma etapa de análise de correlação canônica para identificar as melhores, em termos de correlação com as variáveis de crédito do SFN, combinações lineares de componentes principais. @colak_tcmb_2019 produzem, a partir de séries filtradas do agregados de crédito, indicadores para monitoramento de períodos de expansão e desaceleração de crédito no setor bancário turco.

Já para níveis abaixo do agregado de crédito, poucos trabalhos foram encontrados. Tangenciando o tema da previsão de saldos de crédito, outros tópicos da economia bancária foram objeto de estudo para previsão de séries temporais. @sezer_financial_2019 produziram revisão de literatura de trabalhos que realizaram previsão de séries temporais financeiras utilizando *deep learning*. @gorodetskaya_machine_2021 propõem o que chamaram de "uma metodologia universal" para aplicação automática de *machine learning* na previsão de séries temporais do setor bancário. Entretanto, nenhum dos trabalhos combinaram estruturas hierárquicas com *machine learning*.

No que diz respeito à previsão de séries temporais em largas hierarquias, @prayoga_top-down_2017 trabalharam na previsão do fluxo de caixa do Banco da Indonésia, utilizando uma hierarquia de 3 níveis. Porém, utilizaram apenas a abordagem *top-down* para reconciliação. Inversamente, @li_hierarchical_2016 compararam dois métodos de *machine learning* para previsão da produção de energia solar no estado da Flórida/EUA, rede neural e SVM, em uma abordagem *bottom-up*, caracterizando ambos trabalhos como de nível único.

## Reconciliação ótima de séries temporais hierárquicas

Previsões pontuais de séries temporais hierárquicas não é um assunto novo. Ao menos desde a década de 70, pesquisas foram publicadas acerca de abordagens *bottom-up* e *top-down*, suas vantagens e desvantagens, e tentativas de se definir qual é o melhor método^[Uma revisão dessa literatura pode ser encontrada em @athanasopoulos_hierarchical_2009.]. Entretanto, é apenas em @hyndman_optimal_2011 que é formalizada uma abordagem prática, via MQO, que utiliza toda a informação disponível.

@hyndman_fast_2016 tentam aperfeiçoar o método usando as variâncias das previsões individuais estimadas (dentro da amostra) como estimativa para a matriz de variância-covariância dos erros de reconciliação, de forma a as utilizar como pesos e realizar a reconciliação ótima por mínimos quadrados ponderados (MQP).

@wickramasuriya_optimal_2019 argumentam que o que de fato interessa é que as previsões reconciliadas tenham o menor erro. Então, corrigem a abordagem de reconciliação ótima para o objetivo de minimização dos erros das previsões reconciliadas $\mathbfit{\tilde{y}_{t+h}}$, ao invés dos erros das previsões individuais $\mathbfit{\hat{y}_{t+h}}$. Dado que isso implica na minimização da variância de $\mathbfit{\tilde{e}_{t+h}}$, ou seja, na minimização do somatório da diagonal, o traço, da matriz de variância-covariância de $\mathbfit{\tilde{e}_{t+h}}$, eles chamaram esse método de Traço Mínimo (MinT, na sigla em inglês). Paralelamente, usam desigualdade triangular para demonstrar que as previsões reconciliadas obtidas por esse método são ao menos tão boas quanto as previsões individuais.

@panagiotelis_forecast_2021 reinterpreta a literatura de coerência e reconciliação de previsões pontuais a partir de uma abordagem geométrica, trazendo provas alternativas para conclusões anteriores ao mesmo tempo em que fornece novos teoremas. Além disso, os autores estendem essa interpretação geométrica para o contexto probabilístico, fornecendo métodos paramétricos e não paramétricos (via *bootstrapping*) para reconciliação de previsões probabilísticas.

@spiliotis_hierarchical_2021 propõem a utilização de *machine learning* para a reconciliação ótima de séries temporais, especificamente os métodos de floresta aleatória e *gradient boosting*. Os autores descrevem como vantagens desse método em relação aos anteriores a descrição de relacionamentos não lineares, performance preditiva e a desnecessidade da utilização de todos os elementos da hierarquia na combinação ótima. Para o conjunto de dados utilizados, os autores afirmam que os métodos de *machine learning*, especialmente o XGBoost, alcançaram, em média, melhor performance que as abordagens de nível único e o *MinT*. Além disso, concluíram que quanto maior é a diferença entre as séries, em todos os níveis hierárquicos, maior são os benefícios da abordagem por *machine learning*.

# RECONCILIAÇÃO DE SÉRIES TEMPORAIS HIERÁRQUICAS E AGRUPADAS

## Notação algébrica

Séries temporais hierárquicas são aquelas que podem ser agregadas ou desagregadas naturalmente em uma estrutura aninhada [@hyndman_forecasting_2021]. Para ilustrar, tome a série do PIB de um país fictício com três estados, cada um com dois municípios. Essa série pode ser desagregada por estado que, por sua vez, pode ser desagregada por município (@fig-h).

![Séries Hierárquicas](img/hierarq.png){#fig-h}

Essa estrutura pode ser representada através de equações para qualquer nível de agregação. Dessa forma, o agregado nacional pode ser descrito pelos agregados dos estados, Equação \eqref{eq:ha}, ou como o agregado dos municípios, Equação \eqref{eq:ha_mun}. Já o agregado para o estado A é representado pela Equação \eqref{eq:haES}.

\begin{align}
y_t &= y_{A,t} + y_{B,t} + y_{C,t} \label{eq:ha} \\
y_t &= y_{AA,t} + y_{AB,t} + y_{BA,t} + y_{BB,t} + y_{CA,t} + y_{CB,t}\label{eq:ha_mun} \\
y_{A,t} &= y_{AA,t} + y_{AB,t}\label{eq:haES}
\end{align}

Alternativamente, podemos descrever a estrutura completa de forma matricial:

$$
\begin{bmatrix}
    y_{t} \\
    y_{A, t} \\
    y_{B, t} \\
    y_{C, t} \\
    y_{AA, t} \\
    y_{AB, t} \\
    y_{BA, t} \\
    y_{BB, t} \\
    y_{CA, t} \\
    y_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\begin{bmatrix}
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 1 \\
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}_{n=10 \times m=6}
\begin{bmatrix}
    y_{AA, t} \\
    y_{AB, t} \\
    y_{BA, t} \\
    y_{BB, t} \\
    y_{CA, t} \\
    y_{CB, t}
\end{bmatrix}_{m=6 \times 1}
$$ {#eq-matriz_hierarquia}

Uma outra forma de desagregarmos o PIB é por atividade econômica --- agricultura, indústrias extrativas, indústria de transformação, eletricidade e gás, construção etc. Essa estrutura não pode ser desagregada naturalmente de uma única maneira, como é a hierarquia de estados e municípios. Não pode ser aninhada por um atributo como a própria geografia. A esse tipo de estrutura dá-se o nome de séries agrupadas.

![Séries Agrupadas](img/agrupadas.png){#fig-a}

Combinando as duas, temos a estrutura de séries hierárquicas agrupadas. Ao contrário da estrutura hierárquica, que só pode ser agregada de uma forma, como com os municípios abaixo dos estados^[Essa estrutura é única no sentido que o somatório dos municípios totaliza o estado, mas não se pode somar estados para totalizar um município. Outro exemplo de estrutura hierárquica é a série de vendas de uma empresa: pode-se agregar as vendas de cada filial para obter o total, mas não o contrário.], a adição da estrutura agrupada pode ocorrer tanto acima (@fig-ha1) quanto abaixo (@fig-ha2) da hierárquica.

![Séries Hierárquicas Agrupadas (a)](img/hier_agrup.png){#fig-ha1}

![Séries Hierárquicas Agrupadas (b)](img/hier_agrup_2.png){#fig-ha2}

Na notação matricial, a estrutura da @fig-ha2 é representada como abaixo. Formalmente, o primeiro membro da igualdade é composto pelo vetor $\mathbfit{y}_t$ $n$-dimensional com todas as observações no tempo $t$ para todos os níveis da hierarquia. O segundo membro é composto pela matriz de soma $\mathbfit{S}$ de dimensão $n \times m$ que define as equações para todo nível de agregação, e pelo vetor $\mathbfit{b}_t$ composta pelas séries no nível mais desagregado.

$$
\mathbfit{y}_t=\mathbfit{Sb}_t
$$ {#eq-vetor_b}

$$
\begin{bmatrix}
    y_{t} \\
    y_{A, t} \\
    y_{B, t} \\
    y_{C, t} \\
    y_{X, t} \\
    y_{Y, t} \\
    y_{AX, t} \\
    y_{AY, t} \\
    y_{BX, t} \\
    y_{BY, t} \\
    y_{CX, t} \\
    y_{CY, t}
\end{bmatrix}_{n=12 \times 1}
=
\begin{bmatrix}
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 1 \\
    1 & 0 & 1 & 0 & 1 & 0 \\
    0 & 1 & 0 & 1 & 0 & 1 \\
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1 \\
\end{bmatrix}_{n=12 \times m=6}
\begin{bmatrix}
    y_{AX, t} \\
    y_{AY, t} \\
    y_{BX, t} \\
    y_{BY, t} \\
    y_{CX, t} \\
    y_{CY, t}
\end{bmatrix}_{m=6 \times 1}
$$ {#eq-matriz_ha}

## Abordagens top-down, bottom-up e middle-out

Talvez as formas mais intuitivas de se pensar em previsões para esses tipos de estrutura sejam as abordagens top-down e bottom-up. Tome a estrutura descrita na @fig-h, por exemplo. Podemos realizar a previsão para o horizonte de tempo $h$ do agregado do PIB, representado no topo da hierarquia por *Total* (@eq-topdown_1), e então distribuir os valores previstos proporcionalmente entre os estados e municípios.

$$
\mathbfit{\hat{y}}_{T+h | T} = E[\mathbfit{y}_{T+h} | \Omega_T]
$$ {#eq-topdown_1}

Essa é a abordagem top-down. Nela, a previsão para os níveis mais desagregados da hierarquia são determinadas por uma proporção $p_i$ do nível agregado. Por exemplo, as previsões para o município AA são dadas pela @eq-topdown_2.

$$
\mathbfit{\tilde{y}}_{AA, T+h | T} = p_{1}\mathbfit{\hat{y}}_{T+h | T}
$$ {#eq-topdown_2}

Para isso, temos de definir uma matriz com todos esses pesos, que, seguindo a formulação de @hyndman_forecasting_2021, chamamos de $\mathbfit{G}$:

$$
\mathbfit{G}
=
\begin{bmatrix}
    p_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}_{m=6 \times n=10}
$$ {#eq-matriz_g}

$\mathbfit{G}$ é uma matriz $m \times n$ que multiplica o vetor $\hat{\mathbfit{y}}_{T+h|T}$ que chamamos de *previsões base*, isto é, as previsões individuais para todos os níveis de agregação. A equação para a abordagem *top-down* será, então:

$$
\mathbfit{\tilde{y}}_{T+h | T} = \mathbfit{SG\hat{y}}_{T+h | T}
$$ {#eq-topdown_3}

Na notação matricial para a estrutura da @fig-h, temos:

$$
\begin{bmatrix}
    \tilde{y}_{t} \\
    \tilde{y}_{A, t} \\
    \tilde{y}_{B, t} \\
    \tilde{y}_{C, t} \\
    \tilde{y}_{AA, t} \\
    \tilde{y}_{AB, t} \\
    \tilde{y}_{BA, t} \\
    \tilde{y}_{BB, t} \\
    \tilde{y}_{CA, t} \\
    \tilde{y}_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\mathbfit{S}_{n \times m}
\begin{bmatrix}
    p_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}_{m=6 \times n=10}
\begin{bmatrix}
    \hat{y}_{T+h|T} \\
    \hat{y}_{A, T+h|T} \\
    \hat{y}_{B, T+h|T} \\
    \hat{y}_{C, T+h|T} \\
    \hat{y}_{AA, T+h|T} \\
    \hat{y}_{AB, T+h|T} \\
    \hat{y}_{BA, T+h|T} \\
    \hat{y}_{BB, T+h|T} \\
    \hat{y}_{CA, T+h|T} \\
    \hat{y}_{CB, T+h|T}
\end{bmatrix}_{n \times 1}
$$ {#eq-matriz_topdown1}

Multiplicando as matrizes $\mathbfit{G}$ e $\mathbfit{\hat{y}}$ obtemos o vetor $\mathbfit{b}_t$^[Ver @eq-vetor_b.], que contém as previsões para os níveis mais desagregados, agora definidas como proporção do total.
$$
\begin{bmatrix}
    \tilde{y}_{t} \\
    \tilde{y}_{A, t} \\
    \tilde{y}_{B, t} \\
    \tilde{y}_{C, t} \\
    \tilde{y}_{AA, t} \\
    \tilde{y}_{AB, t} \\
    \tilde{y}_{BA, t} \\
    \tilde{y}_{BB, t} \\
    \tilde{y}_{CA, t} \\
    \tilde{y}_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\mathbfit{S}_{n=10 \times m=6}
\begin{bmatrix}
    p_1\hat{y}_{T+h|T} \\
    p_2\hat{y}_{T+h|T} \\
    p_3\hat{y}_{T+h|T} \\
    p_4\hat{y}_{T+h|T} \\
    p_5\hat{y}_{T+h|T} \\
    p_6\hat{y}_{T+h|T}
\end{bmatrix}_{m \times 1}
$$ {#eq-matriz_topdown2}

Note que, por se tratar de um método *top-down*, é necessário apenas o primeiro elemento do vetor de previsões base, ou seja, a previsão do nível mais agregado (@eq-matriz_topdown2). Sendo essa exatamente uma das vantagens do método *top-down*, na prática, podemos anular os demais elementos de $\mathbfit{\hat{y}}$.

$$
\begin{bmatrix}
    \tilde{y}_{t} \\
    \tilde{y}_{A, t} \\
    \tilde{y}_{B, t} \\
    \tilde{y}_{C, t} \\
    \tilde{y}_{AA, t} \\
    \tilde{y}_{AB, t} \\
    \tilde{y}_{BA, t} \\
    \tilde{y}_{BB, t} \\
    \tilde{y}_{CA, t} \\
    \tilde{y}_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\mathbfit{S}_{n \times m}
\begin{bmatrix}
    p_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    p_6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}_{m=6 \times n=10}
\begin{bmatrix}
    \hat{y}_{T+h|T} \\
    0 \\
    0 \\
    0 \\
    0 \\
    0 \\
    0 \\
    0 \\
    0 \\
    0
\end{bmatrix}_{n=10 \times 1}
$$ {#eq-matriz_topdown3}

Substituindo a matriz $\mathbfit{S}$, temos as equações que definem as previsões reconciliadas.

$$
\begin{bmatrix}
    \tilde{y}_{t} \\
    \tilde{y}_{A, t} \\
    \tilde{y}_{B, t} \\
    \tilde{y}_{C, t} \\
    \tilde{y}_{AA, t} \\
    \tilde{y}_{AB, t} \\
    \tilde{y}_{BA, t} \\
    \tilde{y}_{BB, t} \\
    \tilde{y}_{CA, t} \\
    \tilde{y}_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\begin{bmatrix}
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 1 \\
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}_{n=10 \times m=6}
\begin{bmatrix}
    p_1\hat{y}_{T+h|T} \\
    p_2\hat{y}_{T+h|T} \\
    p_3\hat{y}_{T+h|T} \\
    p_4\hat{y}_{T+h|T} \\
    p_5\hat{y}_{T+h|T} \\
    p_6\hat{y}_{T+h|T}
\end{bmatrix}_{m=6 \times 1}
$$ {#eq-matriz_topdown3}

Já a abordagem bottom-up parte do raciocínio inverso e define as previsões de cada elemento da estrutura a partir das previsões dos elementos mais desagregados. Para tanto, basta modificar a matriz $\mathbfit{G}$.

$$
\mathbfit{G}
=
\begin{bmatrix}
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}_{m=6 \times n=10}
$$ {#eq-matriz_gbu}

Portanto, $\mathbfit{G}$ define a abordagem --- se *top-down* ou *bottom-up* ---, e $\mathbfit{S}$ define a maneira da qual as previsões são somadas para formar as equações de previsão para cada elemento da estrutura. Portanto, chamamos $\mathbfit{G}$ de matriz de reconciliação.

$$
\begin{bmatrix}
    \tilde{y}_{t} \\
    \tilde{y}_{A, t} \\
    \tilde{y}_{B, t} \\
    \tilde{y}_{C, t} \\
    \tilde{y}_{AA, t} \\
    \tilde{y}_{AB, t} \\
    \tilde{y}_{BA, t} \\
    \tilde{y}_{BB, t} \\
    \tilde{y}_{CA, t} \\
    \tilde{y}_{CB, t}
\end{bmatrix}_{n=10 \times 1}
=
\begin{bmatrix}
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 1 \\
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}_{n=10 \times m=6}
\begin{bmatrix}
    \hat{y}_{AA, T+h|T} \\
    \hat{y}_{AB, T+h|T} \\
    \hat{y}_{BA, T+h|T} \\
    \hat{y}_{BB, T+h|T} \\
    \hat{y}_{CA, T+h|T} \\
    \hat{y}_{CB, T+h|T}
\end{bmatrix}_{m=6 \times 1}
$$ {#eq-matriz_bottomup}

## Coerência e reconciliação

Seja somando as previsões do nível mais desagregado para formar os níveis superiores da hierarquia (*bottom-up*) ou distribuindo proporcionalmente as previsões do nível mais agregado (*top-down*), o vetor $\mathbfit{\tilde{y}}_t$ representa as previsões *coerentes*. Isso significa que as previsões são totalizadas corretamente --- as previsões de cada elemento agregado corresponde ao somatório das previsões dos níveis inferiores da hierarquia. Isso é garantido pela multiplicação das matrizes $\mathbfit{SG}$.

Não fosse essa pré multiplicação, nada garantiria a coerência das previsões. Tomando a estrutura da @fig-h como exemplo, seria um acaso improvável que as previsões do agregado para o estado do Espírito Santo fossem exatamente a soma das previsões individuais de seus municípios. Isso porque não há qualquer razão para que cada série siga o mesmo processo estocástico.

Os métodos de gerar previsões coerentes ($\mathbfit{\tilde{y}_t}$) a partir de previsões base ($\mathbfit{\hat{y}_t}$) são chamados de métodos de *reconciliação*. Os métodos de reconciliação tradicionais apresentados, *top-down* e *bottom-up*, utilizam informação limitada. No método *top-down*, utiliza-se apenas informações do nível mais agregado --- por isso, apenas a primeira coluna em (@eq-matriz_g) é diferente de zero. Já na abordagem *bottom-up*, utiliza-se apenas as informações dos níveis mais desagregados, o que resulta na submatriz identidade $m \times m$ na @eq-matriz_gbu, enquanto as colunas que representam os níveis mais agregados são nulas.

Alternativamente, podemos pensar numa matriz $\mathbfit{G}$ qualquer que utilize toda a informação disponível e tenha algumas propriedades que garantam que as previsões coerentes tenham o menor erro o possível. Esse é o problema de pesquisa trabalhado na *reconciliação ótima*.

# METODOLOGIA

Neste capítulo estão contidas explicações sobre os dados e variáveis, sobre o *design* da modelagem e sobre a avaliação dos modelos.

O *software* usado foi o R [@R-base]. As previsões base e os métodos de reconciliação analíticos foram realizados com o pacote {fable} [@R-fable] e suas extensões. Já metodologia de *machine learning* (reamostragem, otimização de hiperparâmetros, treino e predição) foi executada com o pacote {mlr3} [@R-mlr3] e suas extensões. As implementações do XGBoost e LightGBM foram realizadas com seus pacotes homônimos {xgboost} [@R-xgboost] e {ligthgbm} [@R-lightgbm], do Elastic Net com o pacote {glmnet} [@R-glmnet], a do Random Forest com o pacote {ranger} [@R-ranger] e a do SVM com o pacote {e1071} [@R-e1071].

## Dados e variáveis

Os dados usados nesse trabalho são dados terciários obtidos do *datalake* público Base dos Dados [@dahis_data_2022]. A fonte primária são os bancos comerciais e múltiplos com carteira comercial que disponibilizam mensalmente os saldos dos principais verbetes do balancete via documento 4500^[Esses documentos são relatórios eletrônicos obrigatórios demandados pelo Bacen às instituições financeiras que permitem ao regulador o conhecimento minucioso dos bancos e de seus clientes.] ao Banco Central do Brasil, que os compila e publica, agrupados por agência bancária e por município, no relatório ESTBAN — Estatística Bancária Mensal e por Município^[https://www4.bcb.gov.br/fis/cosif/estban.asp?frame=1].

O que compõe os verbetes de crédito, ou seja, os valores das séries temporais a serem trabalhadas, são os saldos de crédito ativo (empréstimos e financiamentos), que correspondem ao principal mais os juros calculados até 59 dias de atraso^[Não são consideradas crédito ativo as operações de crédito liquidadas ou que tenham sido transferidas para prejuízo. São transferidas para prejuízo as operações de crédito em atraso há mais 6 meses após sua classificação de risco em H, que é a mínima [@conselho_monetario_nacional_resolucao_1999].].

Além das estatísticas bancárias, foram obtidas informações de regiões, mesorregiões e microrregiões dos estados, também a partir *datalake* Base dos Dados, com o objetivo de enriquecer a estrutura hierárquica dos dados do ESTBAN, limitada aos municípios.

Uma vez que o escopo deste trabalho se encerra ao Espírito Santo e ao Banestes, foram aplicados os filtros para UF e na raiz do CNPJ. Ademais, foram selecionados os principais verbetes, que são *empréstimos e títulos descontados* e *financiamentos*, e mantidas apenas as agências atualmente em atividade. Quanto ao período, há dados disponíveis desde 1988. Entretanto, utilizaremos os dados a partir de 2003 pois, se tratando de uma hierarquia larga, o custo computacional deve ser levado em conta. Por essa razão, apesar do Banestes contar com 134 agências, foram mantidas apenas as agências com série completa, ou seja, que já estavam em atividade em 2003.

Por fim, as variáveis mantidas no *dataset* foram as descritas no Quadro \ref{tab:qdr-variaveis}. Dessa forma, temos séries mensais de saldos de créditos de `r with(subset(estban, !is_aggregated(cnpj_agencia)), length(unique(cnpj_agencia)))` agências bancárias, distribuídas por `r with(subset(estban, !is_aggregated(nome)), length(unique(nome)))` municípios, a partir de `r format(min(estban$ref), "%B de %Y")`, totalizando `r scales::number(nrow(subset(estban, !is_aggregated(cnpj_agencia) & !is_aggregated(verbete))), big.mark = ".", decimal.mark = ",")` observações.

```{r}
#| tbl-cap: "Variáveis do banco de dados"
#| label: qdr-variaveis
#| include: false

tibble::tribble(
  ~Variável, ~Descrição,
  "ref", "Data de referência do relatório ESTBAN",
  "nome mesorregiao", "Nome da mesorregião do ES",
  "nome microrregiao", "Nome da microrregião do ES",
  "verbete", "Descrição da rubrica do balancete",
  "nome", "Nome do município",
  "cnpj agencia", "CNPJ da agência bancária",
  "saldo", "Saldo do verbete"
) |>
  kbl(booktabs = TRUE, row.names = FALSE, format = "latex", caption = "Variáveis do dataset", label = "qdr-variaveis") |>
  kable_styling(latex_options = c("striped"), font_size = 12) |>
  column_spec(2, width = "10cm")
```

```{=latex}
\begin{quadro}

  \caption{\label{tab:qdr-variaveis}Variáveis do dataset}
  \centering
  \fontsize{12}{14}\selectfont
  \begin{tabular}[t]{l>{\raggedright\arraybackslash}p{10cm}}
  \toprule
  Variável & Descrição\\
  \midrule
  \cellcolor{gray!6}{ref} & \cellcolor{gray!6}{Data de referência do relatório  ESTBAN}\\
  nome mesorregiao & Nome da mesorregião do ES\\
  \cellcolor{gray!6}{nome microrregiao} & \cellcolor{gray!6}{Nome da microrregião   do ES}\\
  verbete & Descrição da rubrica do balancete\\
  \cellcolor{gray!6}{nome} & \cellcolor{gray!6}{Nome do município}\\
  \addlinespace
  cnpj agencia & CNPJ da agência bancária\\
  \cellcolor{gray!6}{saldo} & \cellcolor{gray!6}{Saldo do verbete}\\
  \bottomrule
  \end{tabular}
\end{quadro}
```

Esses dados então são organizados de forma hierárquica por estado, mesorregião, microrregião, município e agência bancária; e, de forma agrupada, por verbete. Isso significa que, para cada nó de agregação, são adicionadas mais três observações ao *dataset*: duas para cada verbete e a terceira para a soma de ambos. Com a estrutura hierárquica e agrupada, o conjunto alcança `r scales::number(nrow(estban))` observações. Por fim, o *dataset* adquiriu a estrutura apresentada na @tbl-dataset.

```{r}
#| label: tbl-dataset
#| tbl-cap: "Estrutura do dataset"

estban |>
  tail(13) |>
  transform(
    # switch decimal e big mark
    saldo = scales::number(
      saldo,
      big.mark = ".", decimal.mark = ","
    ),
    # substitui "_" por espaço em todas as colunas
    verbete = gsub("_", " ", verbete),
    municipio = gsub("_", " ", nome),
    microrregiao = gsub("_", " ", nome_microrregiao),
    mesorregiao = gsub("_", " ", nome_mesorregiao),
    agencia = cnpj_agencia
  ) |>
  subset(
    select = c(
      ref,
      mesorregiao,
      microrregiao,
      municipio,
      agencia,
      verbete,
      saldo
    )
  ) |>
  kbl(
    booktabs = TRUE,
    row.names = FALSE
  ) |>
  kable_styling(latex_options = c("striped", "scale_down"))
```

## Análise exploratória dos dados

O estado do Espírito Santo está localizado no sudeste brasileiro e é dividido em 78 municípios, que estão agrupados em 4 mesorregiões e 13 microrregiões.

::: {#fig-mapas-es layout-ncol=2}

![Posição no Brasil](img/mapa-brasil.png){#fig-mapa-brasil}

![Micro e mesorregiões](img/mapa-microrregioes.png){#fig-mapa-es}

![Quantidade de agências por município](img/mapa-municipalidades.png){#fig-mapa-municipalidades}

O Estado do Espírito Santo e suas meso e microrregiões.
:::

As microrregiões que compõem cada mesorregião são apresentadas na @tbl-microrregioes e na @fig-mapa-es. Já os municípios que compõem cada microrregião são apresentados na @tbl-municipios. A @fig-mapa-municipalidades mostra a quantidade de agências por município.

```{r}
#| label: tbl-microrregioes
#| tbl-cap: "Microrregiões por mesorregião"

aggregate(
  as.character(nome_microrregiao) ~ as.character(nome_mesorregiao),
  data = subset(estban, !is_aggregated(nome_mesorregiao) & !is_aggregated(nome_microrregiao)),
  FUN = function(x) paste(unique(x), collapse = ", ")
) |>
  #substituir "_" por espaço
  transform(
    nome_mesorregiao = gsub("_", " ", `as.character(nome_mesorregiao)`),
    nome_microrregiao = gsub("_", " ", `as.character(nome_microrregiao)`)
  ) |>
  subset(select = c(nome_mesorregiao, nome_microrregiao)) |>
  kbl(
    booktabs = TRUE,
    row.names = FALSE,
    col.names = c(
      "Mesorregião",
      "Microrregiões"
    )
  ) |>
  kable_styling(latex_options = c("striped"))
```

```{r}
#| label: tbl-municipios
#| tbl-cap: "Municípios por microrregião"

aggregate(
  as.character(nome) ~ as.character(nome_microrregiao),
  data = subset(estban, !is_aggregated(nome) & !is_aggregated(nome_microrregiao)),
  FUN = function(x) paste(unique(x), collapse = ", ")
) |>
  # substituir "_" por espaço
  transform(
    nome_microrregiao = gsub("_", " ", `as.character(nome_microrregiao)`),
    nome = gsub("_", " ", `as.character(nome)`)
  ) |>
  subset(select = c(nome_microrregiao, nome)) |>
  kbl(
    booktabs = TRUE,
    row.names = FALSE,
    col.names = c(
      "Microrregiões",
      "Municípios"
    )
  ) |>
  kable_styling(latex_options = c("striped"), font_size = 10) |>
  column_spec(2, width = "10cm")
```

Na amostra selecionada para este trabalho, com exceção dos municípios de Colatina e Cachoeiro de Itapemirim, que contam com 2 agências cada, todos os demais municípios no interior contam com uma única agência. Já na microrregião da capital Vitória, se encontram municípios com múltiplas unidades. Isso pode afetar a decisão de incluir ou não o nível de município na hierarquia.

O tamanho de uma estrutura hierárquica, em termos de observações, é determinada por seu nível mais desagregado. Assim, sendo `r length(unique(estban$ref))` meses e `r length(unique(subset(estban, !is_aggregated(cnpj_agencia))$cnpj_agencia))` agências, a estrutura hierárquica deve contar com `r length(unique(estban$ref))`\times`r length(unique(subset(estban, !is_aggregated(cnpj_agencia))$cnpj_agencia))` $=$ `r scales::number(length(unique(estban$ref)) * length(unique(subset(estban, !is_aggregated(cnpj_agencia))$cnpj_agencia)), big.mark = ".", decimal.mark = ",")` observações. Sendo também uma estrutura agrupada por `r length(unique(subset(estban, !is_aggregated(verbete))$verbete))` verbetes, a quantidade de observações é multiplicada pela quantidade de níveis transversais, totalizando as `r scales::number(length(unique(estban$ref)) * length(unique(subset(estban, !is_aggregated(cnpj_agencia))$cnpj_agencia)) * length(unique(subset(estban, !is_aggregated(verbete))$verbete)), big.mark = ".", decimal.mark = ",")` observações do *dataset* antes da adição dos nós de agregação. Portanto, podemos atestar a completude das séries temporais sem a necessidade de qualquer inspeção adicional.

```{r skim}
#| label: tbl-estban
#| tbl-cap: "Contagem de únicos no dataset ESTBAN"

temp = lapply(
  subset(estban, !is_aggregated(cnpj_agencia) & !is_aggregated(verbete))[sapply(estban, function(x) !is.numeric(x))],
  unique
) |>
  lengths()

 # substituir "_" por espaço
names(temp) = gsub("_", " ", names(temp))

temp |>  
  kbl(booktabs = TRUE, col.names = "Únicos") |>
  kable_styling(latex_options = c("striped"))
```

A série temporal do agregado de crédito no Banestes no Espírito Santo é apresentada na @fig-agregado. Como frequentemente ocorre em séries temporais de natureza social, a inspeção visual sugere a presença de quebras estruturais na média^[Aqui, destacam-se os períodos de 2008 a 2010, que corresponde à crise financeira global; de 2014 a 2016, que corresponde à crise econômica brasileira, e; a partir de 2020 com a pandemia do Covid-19. Também é sugestivo que a forma como o governo se comporta durante esses eventos pode ter impacto direto no comportamento do crédito.]. Essas quebras podem afetar a qualidade das previsões base a serem reconciliadas.

```{r}
#| label: fig-agregado
#| fig-cap: "Série temporal do agregado de crédito do Banestes no ES"

# plot agregado
estban |>
  dplyr::filter(
    is_aggregated(nome),
    is_aggregated(cnpj_agencia),
    is_aggregated(nome_mesorregiao),
    is_aggregated(nome_microrregiao),
    is_aggregated(verbete)
  ) |>
  ggplot(aes(x = ref, y = saldo)) +
  geom_line(color = cores$azul_banestes) +
  scale_y_continuous(labels = scales::number_format(scale = 1 / 1e9)) +
  labs(x = "", y = "Saldo (em R$ bi)") +
  tema
```

Em relação à distribuição, a mesorregião Central Espírito-santense concentra mais crédito do que o somatório das demais regiões (@fig-meso), sendo a microrregião de Vitória a responsável por essa concentração (@fig-micro). Na ótica dos verbetes, o crédito para financiamentos é uma pequena fração do saldo de empréstimos, independentemente da mesorregião (@fig-verbetes e @fig-verbete-meso). 

```{r}
#| label: fig-meso
#| fig-cap: "Série temporal do agregado de crédito do Banestes por mesorregião do ES"

# plot agregado
estban |>
  dplyr::filter(
    is_aggregated(nome),
    is_aggregated(cnpj_agencia),
    !is_aggregated(nome_mesorregiao),
    is_aggregated(nome_microrregiao),
    is_aggregated(verbete)
  ) |>
  # substituir "_" por espaço
  transform(
    nome_mesorregiao = gsub("_", " ", nome_mesorregiao),
    nome_microrregiao = gsub("_", " ", nome_microrregiao),
    nome = gsub("_", " ", nome),
    cnpj_agencia = gsub("_", " ", cnpj_agencia),
    verbete = gsub("_", " ", verbete)
  ) |>
  ggplot(aes(x = ref, y = saldo)) +
  geom_line(color = cores$azul_banestes) +
  scale_y_continuous(labels = scales::number_format(scale = 1 / 1e9)) +
  scale_x_yearmonth(date_labels = "%Y") +
  facet_wrap(~ factor(nome_mesorregiao), scales = "free_y") +
  labs(x = "", y = "Saldo (em R$ bi)") +
  tema +
  theme(
    legend.text = element_text(size = 6),
    legend.title = element_text(size = 6),
    strip.text = element_text(size = 6)
  )
```

```{r}
#| label: fig-micro
#| fig-cap: "Série temporal do agregado de crédito do Banestes por microrregião do ES"

# plot agregado
temp = estban |>
  subset(
    is_aggregated(nome)
    & is_aggregated(cnpj_agencia)
    & !is_aggregated(nome_mesorregiao)
    & !is_aggregated(nome_microrregiao)
    & is_aggregated(verbete)
  ) |>
  # substituir "_" por espaço
  transform(
    nome_mesorregiao = gsub("_", " ", nome_mesorregiao),
    nome_microrregiao = gsub("_", " ", nome_microrregiao),
    nome = gsub("_", " ", nome),
    cnpj_agencia = gsub("_", " ", cnpj_agencia),
    verbete = gsub("_", " ", verbete)
  ) |>
  transform(
    nome_mesorregiao = as.character(nome_mesorregiao),
    nome_microrregiao = as.character(nome_microrregiao),
    nome = as.character(nome),
    cnpj_agencia = as.character(cnpj_agencia),
    verbete = as.character(verbete)
  )

plots = temp |>
  by(INDICES = temp$nome_mesorregiao, FUN = function(x) {
    g = ggplot(x, aes(x = ref, y = saldo, color = factor(nome_microrregiao))) +
      geom_line() +
      scale_y_continuous(labels = scales::number_format(scale = 1 / 1e6)) +
      scale_x_yearmonth(date_labels = "%Y") +
      scale_color_manual(values = unlist(cores, use.names = FALSE)) +
      facet_wrap(~ factor(nome_mesorregiao), scales = "free_y") +
      labs(x = "", y = "Saldo (em R$ mi)", color = "microrregião") +
      tema +
      theme(
        legend.key.size = unit(0.2, "cm"),
        legend.background = element_rect(fill = alpha("white", 0)),
        legend.title = element_text(size = 6),
        legend.text = element_text(size = 6),
        legend.position = c(0.08, 0.9),
        legend.justification = c(0.08, 0.9),
        strip.text = element_text(size = 6),
      )
  })

do.call(gridExtra::grid.arrange, c(plots, ncol = 2))
```

```{r}
#| label: fig-verbetes
#| fig-cap: "Verbetes no agregado do ES"

# plot por verbetes
estban |>
  dplyr::filter(
    is_aggregated(nome),
    is_aggregated(cnpj_agencia),
    is_aggregated(nome_mesorregiao),
    is_aggregated(nome_microrregiao),
    !is_aggregated(verbete)
  ) |>
  # substituir "_" por espaço
  transform(
    nome_mesorregiao = gsub("_", " ", nome_mesorregiao),
    nome_microrregiao = gsub("_", " ", nome_microrregiao),
    nome = gsub("_", " ", nome),
    cnpj_agencia = gsub("_", " ", cnpj_agencia),
    verbete = gsub("_", " ", verbete)
  ) |>
  ggplot(aes(x = ref, y = saldo, color = factor(verbete))) +
  geom_line() +
  scale_y_continuous(labels = scales::number_format(scale = 1 / 1e9)) +
  scale_color_manual(values = unlist(cores, use.names = FALSE)) +
  labs(x = "", y = "Saldo (em R$ bi)", color = "Verbete") +
  tema
```

```{r}
#| label: fig-verbete-meso
#| fig-cap: "Verbete por mesorregião do ES"

# plot por mesorregião
estban |>
  dplyr::filter(
    is_aggregated(nome),
    is_aggregated(cnpj_agencia),
    !is_aggregated(nome_mesorregiao),
    is_aggregated(nome_microrregiao),
    !is_aggregated(verbete)
  ) |>
  # substituir "_" por espaço
  transform(
    nome_mesorregiao = gsub("_", " ", nome_mesorregiao),
    nome_microrregiao = gsub("_", " ", nome_microrregiao),
    nome = gsub("_", " ", nome),
    cnpj_agencia = gsub("_", " ", cnpj_agencia),
    verbete = gsub("_", " ", verbete)
  ) |>
  ggplot(aes(x = ref, y = saldo, color = factor(verbete))) +
  geom_line() +
  facet_wrap(~ factor(nome_mesorregiao), scales = "free_y") +
  scale_y_continuous(labels = scales::number_format(scale = 1 / 1000000)) +
  scale_x_yearmonth(date_labels = "%Y") +
  scale_color_manual(values = unlist(cores, use.names = FALSE)) +
  labs(x = "", y = "Saldo (em R$ mi)", color = "Verbete") +
  tema +
  theme(
    legend.text = element_text(size = 6),
    legend.title = element_text(size = 6),
    strip.text = element_text(size = 6)
  )
```

## Previsões base {#sec-previsoes_base}

Uma vez que o foco deste trabalho está no incremento de performance proporcionado pela reconciliação ótima sobre um conjunto de previsões base e não na qualidade destas, elas foram obtidas por meio de métodos básicos para previsão de séries temporais, especificamente o algoritmo de Hyndman-Koehler-Snyder-Grose para suavimento exponencial (ETS) [@hyndman_state_2002], sem tratamentos adicionais para *outliers*, quebras estruturais ou transformações. Esses métodos são amplamente utilizados na literatura de séries temporais e, portanto, servem como *benchmark* para a avaliação dos métodos de reconciliação ótima.

Os modelos foram treinados com dados de 2003 a 2021 e as previsões foram realizadas para o ano de 2022 (@fig-modelagem-1). Para verificar a qualidade básica do ajuste, foram realizados testes de Ljung-Box para os resíduos das previsões. Os resultados são apresentados na @tbl-lb-pvalue. Considerando nível de significância de $\alpha=0.05$ e 12 defasagens, cerca de 80% dos modelos não rejeitam a hipótese nula de que os resíduos são ruído branco. Isso sugere que os modelos de previsão base são, em sua maior parte, adequados para o propósito deste trabalho.

![Previsões base](img/modelagem_1.png){#fig-modelagem-1 width=70%}

```{r}
#| label: tbl-lb-pvalue
#| tbl-cap: "Resultados do teste de Ljung-box para as previsões base ($\\alpha = 0.05$)"

testes_lb = readRDS("data/estban/previsoes_base/testes_lb.rds") |>
  transform(h_0 = ifelse(lb_pvalue < 0.05, "rejeita", "não rejeita"))

prop.table(table(testes_lb$h_0)) |>
  kbl(booktabs = TRUE, col.names = c("Resultado", "Proporção")) |>
  kable_styling(latex_options = c("striped"))
```

## *Design* do experimento

O objetivo do experimento consiste em comparar o ganho de desempenho dos métodos de reconciliação em relação às previsões base, ou seja, dada a performance das previsões individuais, o quanto mais precisas elas se tornam ao aplicar um determinado método de reconciliação. Para isso, serão utilizadas a abordagem de nível único *bottom-up*^[Como o *dataset* Estban é agrupado, a desagregação não é única e as abordagem *top-down* e *middle-out* não podem ser aplicadas [@athanasopoulos_forecast_2023].], o método analítico de reconciliação ótima *MinT-Shrink* e os métodos de reconciliação ótima baseados em *machine learning*: *gradient boosting* (*Xgboost* e *LightGBM*), *Random Forest*, *Elastic Net* (Lasso, *Ridge* e *Elastic Net*) e *Support Vector Machines*.

A metodologia para obtenção das previsões reconciliadas por métodos baseados em *machine-learning* será semelhante ao de @spiliotis_hierarchical_2021. Ela consiste em:

1. Previsão contínua (*rolling forecast*):
A amostra treino é separada em $p$ subamostras para todas as séries em todos os níveis de agregação, com a primeira separação abrangindo $y_1$ até $Y_Q$, a segunda $y_1$ até $Y_{Q+1}$ e assim sucessivamente até a última separação abrangendo $y_1$ até $Y_{Q+p-1}$. Para cada subamostra foi treinado um modelo (de mesmo algoritmo usado na [seção @sec-previsoes_base]) e obtida previsão um passo a frente. Para este trabalho, a amostra treino foi divida em 50%, com $Q=120$ e $p=108$.

    ![Esquema de modelagem de previsões contínuas](img/modelagem_2.png){#fig-modelagem-2 width=70%}

1. Treino dos modelos de *machine learning*:
Para cada série do nível mais desagregado, $y_m$, é treinado um modelo de ML com $n+1$ variáveis, compostas pelas $n$ séries — que incluem todos os níveis de agregação —, mais a própria $y_m$ como *target* (@tbl-modelagem). Cada uma das $n$ séries contam com $p$ previsões obtidas no passo 1. Isso resulta em um modelo de reconciliação ótima para cada elemento do menor nível da hierarquia, combinando informações disponíveis de todos os níveis hierárquicos.
    
1. Reconciliação ótima:
Com os modelos treinados, passa-se as previsões base obtidas na [seção @sec-previsoes_base] como regressores para se obter as previsões reconciliadas das séries do nível mais desagregado $\tilde{y}_m$.

1. Agregação: Assim como nos métodos analíticos de combinação ótima, a obtenção das previsões reconciliadas para os demais níveis de hierárquicos $\tilde{y}_n$ se dá através da agregação  semelhante ao *bottom-up*, mas ao invés de se somar as previsões base $\hat{y}_m$, somam-se as previsões reconciliadas $\tilde{y}_m$.

```{r}
#| label: tbl-modelagem
#| tbl-cap: "Conjunto de dados para predição dos modelos de ML"
  tibble::tribble(
    ~Target, ~`Variável 1`, ~`Variável 2`, ~..., ~`Variável n`,
    "$y_{1,Q+1}$", "$\\hat{y}_{1,Q+1}$", "$\\hat{y}_{2,Q+1}$", "...", "$\\hat{y}_{n,Q+1}$",
    "$y_{2,Q+2}$", "$\\hat{y}_{1,Q+2}$", "$\\hat{y}_{2,Q+2}$", "...", "$\\hat{y}_{n,Q+2}$",
    "...", "...", "...", "...", "...",
    "$y_{m,Q+p}$", "$\\hat{y}_{1,Q+p}$", "$\\hat{y}_{2,Q+p}$", "...", "$\\hat{y}_{n,Q+p}$"
  ) |>
  kbl(booktabs = TRUE, escape = FALSE) |>
  kable_styling(latex_options = c("striped"))
```

Dessa forma, essa metodologia é semelhante à aplicada na reconciliação ótima analítica, se afastando principalmente em três pontos: (i) a utilização de algoritmos de ML ao invés de MQG, (ii) a não atribuição de peso de forma obrigatória para todos os nós da hierarquia e (iii) no ajuste de um modelo individual para cada série do nível mais desagregado, permitindo maior especialização e sendo capaz de se adaptar melhor aos diferentes padrões de cada série (@spiliotis_hierarchical_2021).

Um ponto negativo na metodologia proposta por @spiliotis_hierarchical_2021 é o processo de *rolling origin* (passo 1). Esse processo requer a realização de previsões para dentro da amostra treino, o que pode ser um problema para séries temporais com poucas observações ou de série incompleta. No caso do *dataset* Estban, algumas das agências foram criadas após o período escolhido para o *split* em $Q$ (dezembro/2012), sendo necessário sua exclusão do dataset e invalidando o uso da metodologia para essas unidades. Nesse sentido, o MinT se mostra uma opção mais viável para aplicações no mundo real.

Nesses casos, uma alternativa para permitir o uso dos métodos de ML é substituir o processo de *rolling origin* e usar os valores ajustados dos modelos das previsões base $\hat{y}$ como input para os modelos de ML. Além de permitir a inclusão de séries incompletas — agências criadas durante o período, no caso do *dataset* Estban —, essa abordagem também aumenta o tamanho da amostra treino em $Q$ observações, o que pode melhorar a performance dos modelos de ML. Chamaremos essa estratégia de *fitted base forecasts*.

Outra possibilidade de substituição do passo 1, caso as séries sejam de tamanho suficiente, é o processo de reajuste. Esse processo consiste no reajuste de um modelo para um novo conjunto de dados, conservando os hiperparâmetros originais porém reestimando os coeficientes (e.g., treina-se um modelo autoregressivo AR($p$) de coeficientes $\phi_p$ e então passa-se um novo conjunto de dados fora da amostra, mantendo o hiperparâmetro $p$ e reestimando $\phi_p$, obtendo novos valores ajustados). Utiliza-se então os valores reajustados para treinar os modelos de ML. Nessa estratégia, doravante denominada de *refit*, os modelos foram treinados até $Q$ e então reajustados para $Q+p$. Uma restrição dessa abordagem é que, fixados os hiperparâmetros anteriores, não necessariamente todos modelos alcançarão convergência no reajuste de seus coeficientes para o novo conjunto de dados.

## Otimização de hiperparâmetros

A maior parte dos métodos de *machine learning* são altamente parametrizáveis, sendo sua performance de generalização (para fora da amostra) sensível à escolha de seus hiperparâmetros. Quando disponível, os hiperparâmetros a serem otimizados e seus espaços de busca seguiram a recomendação em @bischl_hyperparameter_2021.

Os conjuntos de hiperparâmetros e seus intervalos são apresentados no Apêndice \ref{apendice_hiperparametros}. Para a otimização, foram utilizadas dois calibradores: (i) busca em grade (com resolução de 10 combinações), mais custoso em tempo de processamento, para os métodos com menor quantidade de hiperparâmetros a serem otimizados, e (ii) otimização bayesiana (na configuração padrão do pacote {mlr3MBO}), mais eficiente para os métodos com maior quantidade de hiperparâmetros. A estratégia de reamostragem utilizada foi a validação cruzada *k-fold* com $k=10$.

A otimização bayesiana foi usada em todos os métodos, exceto no *elastic net*, uma vez que apenas um (no caso do *lasso* e *ridge*) ou dois hiperparâmetros foram otimizados. A medida de performance utilizada para a otimização foi a raiz do erro quadrático médio (*root mean squared error* — RMSE).

Por fim, cada modelo foi calibrado individualmente, ou seja, cada agência possui um conjunto de hiperparâmetros otimizados para cada um dos 7 métodos de ML empregados para reconciliação ótima.

```{r, include = FALSE, eval = FALSE}

tibble::tribble(
  ~Hiperparâmetro, ~Descrição, ~Intervalo, ~Trafo,
  "nrounds", "Número de iterações", "$[1, 5000]$", NULL,
  "eta", "Taxa de aprendizado", "$[-4, 0]$", "$10^x$",
  "max\\_depth", "Profundidade máxima", "$[1, 20]$", NULL,
  "subsample", "Subamostra", "$[0.1, 1]$", NULL,
  "colsample\\_bytree", "Subamostra de colunas para uma árvore", "$[0.1, 1]$", NULL,
  "colsample\\_bylevel", "Subamostra de colunas por nível de profundidade", "$[0.1, 1]$", NULL,
  "lambda", "Regularização L2", "$[-10, 10]$", "$2^x$",
  "alpha", "Regularização L1", "$[-10, 10]$", "$2^x$"
) |>
  kbl(
    booktabs = TRUE,
    escape = FALSE,
    format = "latex",
    label = "tbl-hip-xgboost",
    caption = "Intervalos de hiperparâmetros para \\{xgboost\\}"
  ) |>
  kable_styling(latex_options = c("striped"))
```

```{r, include = FALSE, eval = FALSE}

tibble::tribble(
  ~Hiperparâmetro, ~Descrição, ~Intervalo, ~Trafo,
  "num\\_iterations", "Número de iterações", "$[1, 1000]$", NULL,
  "boosting", "Algoritmo de boosting", "\\{gbdt, dart, goss\\}", NULL,
  "learning\\_rate", "Taxa de aprendizado", "$[-4, 0]$", "$10^x$",
  "num\\_leaves", "Número de folhas", "$[2, 20]$", NULL,
  "lambda\\_l1", "Regularização L1", "$[-12, 12]$", "$2^x$",
  "lambda\\_l2", "Regularização L2", "$[-12, 12]$", "$2^x$",
  "feature\\_fraction", "Subamostra de colunas", "$[0.1, 1]$", NULL,
  "bagging\\_fraction", "Subamostra de linhas", "$[0.1, 1]$", NULL,
  "bagging\\_freq", "Frequência de amostragem", "$[1, 10]$", NULL
) |>
  kbl(
    booktabs = TRUE,
    escape = FALSE,
    format = "latex",
    label = "tbl-hip-lightgbm",
    caption = "Intervalos de hiperparâmetros para \\{lightgbm\\}"
  ) |>
  kable_styling(latex_options = c("striped"))
```

```{r, include = FALSE, eval = FALSE}

tibble::tribble(
  ~Hiperparâmetro, ~Descrição, ~Intervalo, ~Trafo,
  "min.node.size", "Número mínimo de observações em um nó terminal", "$[1,7]$", "$2^x$",
  "mtry", "Número de variáveis candidatas para split", "$[1,)$", NULL,
  "replace", "Amostragem com reposição", "\\{TRUE, FALSE\\}", NULL,
  "sample.fraction", "Fração de observações a serem amostradas", "$[0.1, 1]$", NULL,
  "num.trees", "Número de árvores", "$[1, 2000]$", NULL
) |>
  kbl(
    booktabs = TRUE,
    escape = FALSE,
    format = "latex",
    label = "tbl-hip-ranger",
    caption = "Intervalos de hiperparâmetros para \\{ranger\\}"
  ) |>
  kable_styling(latex_options = c("striped", "scale_down"))
```

```{r, include = FALSE, eval = FALSE}

tibble::tribble(
  ~Hiperparâmetro, ~Descrição, ~Intervalo, ~Trafo,
  "cost", "Custo de $\\xi$", "$[0, 1]$", "$2^x$",
  "kernel", "Kernel", "\\{linear, polynomial, radial, sigmoid\\}", NULL,
  "degree", "Grau do polinômio", "$[1, 5]$", NULL,
  "gamma", "Influência amostral", "$[-12, 12]$", "$2^x$",
  "type", "Tipo de SVM", "\\{eps-regression\\}", NULL
) |>
  kbl(
    booktabs = TRUE,
    escape = FALSE,
    format = "latex",
    label = "tbl-hip-svm",
    caption = "Intervalos de hiperparâmetros para \\{e1071\\} (svm)"
  ) |>
  kable_styling(latex_options = c("striped"))
```

```{r, include = FALSE, eval = FALSE}

tibble::tribble(
  ~Hiperparâmetro, ~Descrição, ~Intervalo, ~Trafo,
  "alpha", "Mix entre lasso e ridge", "$[0, 1]$", NULL,
  "lambda", "Regularização", "$[-12, 12]$", "$2^x$"
) |>
  kbl(
    booktabs = TRUE,
    escape = FALSE,
    format = "latex",
    label = "tbl-hip-glmnet",
    caption = "Intervalos de hiperparâmetros para \\{glmnet\\}"
  ) |>
  kable_styling(latex_options = c("striped"))
```

# RESULTADOS

As tabelas a seguir apresentam os resultados obtidos para o experimento. Para fins de comparação, além do *dataset* de interesse, o ESTBAN, o experimento foi executado também para o *dataset* TOURISM, disponível no pacote {tsibble} [@R-tsibble], e seus resultados reportados na [seção @sec-tourism].

As @tbl-estban-results-analiticos e @tbl-tourism-results-analiticos contém as medidas de acurácia RMSSE e MASE para os métodos analíticos de reconciliação ótima BU (*bottom-up*) e MinT, e para as previsões base, ou seja, sem aplicar qualquer método de reconciliação. A primeira coluna especifica o método utilizado, enquanto as demais colunas apresentam a média da performance em cada nível de agregação.

As @tbl-estban-results-ml-rolling, @tbl-estban-results-ml-fitted, @tbl-estban-results-ml-refit, @tbl-tourism-results-ml-rolling e @tbl-tourism-results-ml-fitted reportam as medidas de acurácia para os métodos de reconciliação ótima baseados em *machine learning*. Já as @tbl-estban-tempo-ml e @tbl-tourism-tempo-ml reportam o tempo de processamento para as etapas de calibragem, treino e predição desses métodos^[Os métodos analíticos não tiveram seu tempo de processamento medidos porque executam quase que instantaneamente, já sinalizando uma vantagem para esses métodos.].

Em geral, os métodos baseados em árvore, além de requererem maior tempo de processamento devido a sua complexidade no espaço de hiperparâmetros, também tenderam a perder qualidade de performance conforme suas previsões são agregadas para formação dos níveis superiores da hierarquia. Contrariamente, os métodos de regressão regularizada e o SVM se mostraram mais robustos à agregação.

Nas tabelas a seguir, **negrito** indica a melhor performance entre os métodos para aquele determinado nível de agregação, e \underline{sublinhado} indica que aquele método de ML superou o método analítico de melhor performance naquele nível de agregação.

## ESTBAN

Nos reportes para o *dataset* ESTBAN estão incluídas as médias de performance para cada nível hierárquico e agrupado. As colunas "agregado", "mesorregiao", "microrregiao", "municipio" e "agencia", fazem referência à estrutura hierárquica, ou seja, tratam o verbete de forma agregada. Já as colunas "verbete", "bottom" e "hierarquia", incluem também a estrutura agrupada, tratando o verbete de forma desagregada. Detalhadamente:

- Agregado: performance do método para a série que representa o total, com os verbetes agregados, (@fig-agregado).
- Mesorregião: a média das performances do método para as séries do agregado de cada mesorregião, com os verbetes agregados (@fig-meso).
- Microrregião: a média das performances do método para as séries do agregado de cada microrregião, com os verbetes agregados (@fig-micro).
- Município: a média das performances do método para as séries do agregado de cada município, com os verbetes agregados.
- Agência: a média das performances do método para as séries de cada agência, com os verbetes agregados.
- Verbete: a média das performances do método para as séries de cada verbete, para o total da hierarquia (@fig-verbetes).
- Bottom: a média das performances do método para as séries do nível mais desagregado, ou seja, verbete por agência.
- Hierarquia: a média das performances do método para todas as séries, agregadas e desagregadas.

Para o *dataset* ESTBAN, não houve uma combinação de método e estratégia que fosse consistentemente melhor ao longo de todos os níveis de agregação. Portanto, a escolha do método e da estratégia a serem utilizados dependerá do objetivo do pesquisador^[Se o objetivo é a elaboração de *guidance*, por exemplo, o pesquisador deve preferir o método e estratégia que geram as  previsões mais precisas para o nível agregado. Já para elaboração de metas individuais, os níveis individuais ou regionais podem ser preferíveis.].

Para os níveis ao topo da hierarquia, os métodos de ML se mostraram a melhor opção para estimação. No nível agregado, o *elastic net* na estratégia *refit* (@tbl-estban-results-ml-refit) se mostrou a melhor opção para a estimação do agregado, com 89% de ganho de performance sobre o MinT (@tbl-estban-results-analiticos), em termos de RMSSE. Da mesma forma, para o nível de mesorregião, o *elastic net* na configuração *lasso* obteve a melhor performance, performando 7% melhor que BU. Por outro lado, tanto nos níveis hierárquicos abaixo, quanto nos níveis agrupados, os métodos de ML não foram capazes de superar os métodos analíticos.

Os resultados se mostraram bastante sensíveis à estratégia utilizada. Na métrica RMSS, nenhum método utilizando as estratégias *rolling forecast* e *fitted base* foi capaz de superar o MinT em qualquer nível de agregação, enquanto na estratégia *refit* os métodos de ML mostraram ganhos de performance com os métodos SVM e nas três configurações do *elastic net*.

Em geral, as medidas RMSSE e MASE se mostraram bastante correlacionadas, com os métodos que obtiveram melhor performance em uma métrica também obtendo melhor performance na outra. A exceção foi para o método *lasso* na estratégia *rolling forecast*, que obteve performance melhor que o MinT, em termos de MASE, para o nível agregado, sendo o único resultado positivo para a estratégia *rolling forecast*.

```{r}
#| tbl-cap: "Resultados Estban: Acurácia dos métodos analíticos de reconciliação"
#| label: tbl-estban-results-analiticos

rbind(
  readRDS("data/estban/preds_analitico/acuracia_analiticos.rds")[["rmsse"]],
  readRDS("data/estban/preds_analitico/acuracia_analiticos.rds")[["mase"]]
 ) |>
  # substituindo "glmnet" por "elastic net"
  transform(
    .model = ifelse(.model == "glmnet", "elastic net", .model)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 3) |>
  pack_rows("MASE", 4, 6) |>
  kable_styling(latex_options = c("striped", "scale_down")) |>
  # microrregião
  column_spec(
    4,
    bold = c(F, T, F, F, T, F)
  ) |>
  # município
  column_spec(
    5,
    bold = c(T, F, F, T, F, F)
  ) |>
  # agência
  column_spec(
    6,
    bold = c(F, F, T, T, F, F)
  ) |>
  # verbete
  column_spec(
    7,
    bold = c(F, F, T, F, F, T)
  ) |>
  # bottom
  column_spec(
    8,
    bold = c(F, F, T, F, T, F)
  ) |>
  # hierarquia
  column_spec(
    9,
    bold = c(F, F, T, F, F, T)
  )
```

```{r}
#| tbl-cap: "Resultados Estban: Acurácia dos métodos de ML de reconciliação. Estratégia rolling forecast."
#| label: tbl-estban-results-ml-rolling

rbind(
  readRDS("data/estban/preds_ml/preds/rolling_forecast/resumo.RDS")[["rmsse"]],
  readRDS("data/estban/preds_ml/preds/rolling_forecast/resumo.RDS")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 7) |>
  pack_rows("MASE", 8, 14) |>
  kable_styling(latex_options = c("striped", "scale_down")) |>
  # agregado
  column_spec(
    2,
    underline = c(F, F, F, F, F, F, F, F, T, F, F, F, F, F)
  )
```

```{r}
#| tbl-cap: "Resultados Estban: Acurácia dos métodos de ML de reconciliação. Estratégia fitted base."
#| label: tbl-estban-results-ml-fitted

rbind(
  readRDS("data/estban/preds_ml/preds/fitted_base/resumo.RDS")[["rmsse"]],
  readRDS("data/estban/preds_ml/preds/fitted_base/resumo.RDS")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 7) |>
  pack_rows("MASE", 8, 14) |>
  kable_styling(latex_options = c("striped", "scale_down"))
```

```{r}
#| tbl-cap: "Resultados Estban: Acurácia dos métodos de ML de reconciliação. Estratégia refit."
#| label: tbl-estban-results-ml-refit

rbind(
  readRDS("data/estban/preds_ml/preds/one-step-ahead/resumo.RDS")[["rmsse"]],
  readRDS("data/estban/preds_ml/preds/one-step-ahead/resumo.RDS")[["mase"]]
 ) |>
  # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 7) |>
  pack_rows("MASE", 8, 14) |>
  kable_styling(latex_options = c("striped", "scale_down")) |>
  # agregado
  column_spec(
    2,
    bold = c(T, F, F, F, F, F, F, T, F, F, F, F, F, F),
    underline = c(F, T, F, F, T, F, F, F, T, F, F, T, F, F)
  ) |>
  # mesorregião
  column_spec(
    3,
    bold = c(F, T, F, F, F, F, F, F, T, F, F, F, F, F)
  )
```

```{r}
#| tbl-cap: "Resultados Estban: Tempo de processamento dos métodos de ML (em horas)"
#| label: tbl-estban-tempo-ml

# obtendo tempo de processamento
tempo = lapply(c("one-step-ahead", "fitted_base", "rolling_forecast"), function(tipo) {
  lapply(c("xgb", "ranger", "glmnet", "lasso", "ridge", "svm", "lightgbm"), function(learner) {
    preds = readRDS(paste0("data/estban/preds_ml/preds/", tipo, "/preds_", learner, ".RDS"))[[2]]
    return(preds)
  })
})

# juntando predições em um único dataframe
tempo = do.call(rbind, tempo)

# convertendo colunas para numérico
tempo = sapply(as.data.frame(tempo), function(x) as.numeric(x))

# nomeando df
colnames(tempo) = c("xgb", "ranger", "elastic net", "lasso", "ridge", "svm", "lightgbm")
rownames(tempo) = c("refit", "fitted base", "rolling forecast")

# tabela
tempo |>
  kbl(booktabs = TRUE, digits = 3) |>
  kable_styling(latex_options = c("striped"))
```

## TOURISM {#sec-tourism}

O *dataset* TOURISM consiste na quantidade trimestral de pernoites em visitas na Austrália entre 1998 e 2016. A estrutura é hierárquica e agrupada, composta por 3 níveis hierárquicos — *State* (Estados), *Region* (Regiões) e total —, e agrupado por *Purpose* (Propósito).

Assim como no *dataset* ESTBAN, aqui também não houve uma combinação de método e estratégia que fosse consistentemente melhor ao longo de todos os níveis de agregação. Entretanto, uma tendência pode foi observada em ambos *datasets*, com os métodos de ML se mostrando a melhor opção para estimação nos níveis ao topo da hierarquia, enquanto os métodos analíticos se mostram melhor opção para os níveis ao fundo da hierarquia.

```{r}
#| tbl-cap: "Resultados Tourism: Acurácia dos métodos analíticos de reconciliação"
#| label: tbl-tourism-results-analiticos

rbind(
  readRDS("data/tourism/preds_analitico/acuracia_analiticos.rds")[["rmsse"]],
  readRDS("data/tourism/preds_analitico/acuracia_analiticos.rds")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    .model = ifelse(.model == "glmnet", "elastic net", .model)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 3) |>
  pack_rows("MASE", 4, 6) |>
  kable_styling(latex_options = c("striped")) |>
  # bottom
  column_spec(
    6,
    bold = c(F, F, T, F, F, T)
  ) |>
  # hierarquia
  column_spec(
    7,
    bold = c(F, F, T, F, F, T)
  )
```

```{r}
#| tbl-cap: "Resultados Tourism: Acurácia dos métodos de ML de reconciliação. Estratégia rolling forecast."
#| label: tbl-tourism-results-ml-rolling

rbind(
  readRDS("data/tourism/preds_ml/preds/rolling_forecast/resumo.RDS")[["rmsse"]],
  readRDS("data/tourism/preds_ml/preds/rolling_forecast/resumo.RDS")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 3) |>
  pack_rows("RMSSE", 1, 7) |>
  pack_rows("MASE", 8, 14) |>
  kable_styling(latex_options = c("striped")) |>
  # agregado
  column_spec(
    2,
    bold = c(F, F, F, F, F, T, F, F, F, F, F, F, T, F),
    underline = c(F, F, F, F, T, F, F, F, F, F, F, T, F, F)
  ) |>
  # state
  column_spec(
    3,
    bold = c(F, F, F, F, F, T, F, F, F, F, F, F, T, F),
    underline = c(F, F, F, F, T, F, F, F, F, F, F, T, F, F)
  ) |>
  # purpose
  column_spec(
    5,
    bold = c(F, F, F, F, F, T, F, F, F, F, F, F, T, F),
    underline = c(F, F, F, F, T, F, F, F, F, F, F, T, F, F)
  )
```

```{r}
#| tbl-cap: "Resultados Tourism: Acurácia dos métodos de ML de reconciliação. Estratégia fitted base."
#| label: tbl-tourism-results-ml-fitted

rbind(
  readRDS("data/tourism/preds_ml/preds/fitted_base/resumo.RDS")[["rmsse"]],
  readRDS("data/tourism/preds_ml/preds/fitted_base/resumo.RDS")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 2) |>
  pack_rows("RMSSE", 1, 7) |>
  pack_rows("MASE", 8, 14) |>
  kable_styling(latex_options = c("striped")) |>
  # state
  column_spec(
    3,
    underline = c(F, F, F, F, T, T, F, F, F, F, F, T, T, F)
  ) |>
  # region
  column_spec(
    4,
    bold = c(F, F, F, F, T, F, F, F, F, F, F, T, F, F)
  ) |>
  # purpose
  column_spec(
    5,
    underline = c(F, F, F, F, F, F, F, F, F, F, F, T, F, F)
  )
```

```{r}
#| tbl-cap: "Resultados Tourism: Acurácia dos métodos de ML de reconciliação. Estratégia refit."
#| label: tbl-tourism-results-ml-refit

rbind(
  readRDS("data/tourism/preds_ml/preds/one-step-ahead/resumo.RDS")[["rmsse"]],
  readRDS("data/tourism/preds_ml/preds/one-step-ahead/resumo.RDS")[["mase"]]
 ) |>
 # substituindo "glmnet" por "elastic net"
  transform(
    modelo = ifelse(modelo == "glmnet", "elastic net", modelo)
  ) |>
  kbl(booktabs = TRUE, format = "latex", digits = 2) |>
  pack_rows("RMSSE", 1, 3) |>
  pack_rows("MASE", 4, 6) |>
  kable_styling(latex_options = c("striped"))
```

```{r}
#| tbl-cap: "Resultados Tourism: Tempo de processamento dos métodos de ML (em horas)"
#| label: tbl-tourism-tempo-ml

# obtendo tempo de processamento
tempo = lapply(c("fitted_base", "rolling_forecast", "one-step-ahead"), function(tipo) {
  lapply(c("xgb", "ranger", "glmnet", "lasso", "ridge", "svm", "lightgbm"), function(learner) {
    preds = readRDS(paste0("data/tourism/preds_ml/preds/", tipo, "/preds_", learner, ".RDS"))[[2]]
    return(preds)
  })
})

# juntando predições em um único dataframe
tempo = do.call(rbind, tempo)

# convertendo colunas para numérico
tempo = sapply(as.data.frame(tempo), function(x) as.numeric(x))

# nomeando df
colnames(tempo) = c("xgb", "ranger", "elastic net", "lasso", "ridge", "svm", "lightgbm")
rownames(tempo) = c("fitted base", "rolling forecast", "refit")

# tabela
tempo |>
  kbl(booktabs = TRUE, digits = 3) |>
  kable_styling(latex_options = c("striped"))
```

<!-- ! BUG: Parece ter um erro nos resultados de Spiliotis. Note que tanto em meus resultados de ML (implementados manualmente) quanto os analíticos (utilizando a implementação do {fabletools}, RMSSE < MASE em ambos Tourism (que conferem com FPP3) quanto Tourism Monthly. Mas, em Spiliotis, RMSSE > MASE tanto para ML quanto os analíticos, indicando que possa haver problemas na execução ou nos dados. -->

# CONCLUSÃO

Neste trabalho, foram apresentados experimentos de reconciliação ótima para séries temporais hierárquicas e agrupadas, utilizando métodos analíticos e de *machine learning* com o objetivo de obter coerência e ganhos de acurácia nas previsões de saldos de empréstimos e financiamentos do Banco do Estado do Espírito Santo. Pesquisas anteriores já haviam mostrado que a reconciliação ótima pode trazer ganhos de acurácia, e que métodos de *machine learning* podem ser competitivos em relação aos métodos analíticos.

Este trabalho trouxe, além dos métodos de floresta aleatória e *gradient boosting* já trabalhados em @spiliotis_hierarchical_2021, o método de regressão regularizada *elastic net* e o *support vector machines*, além de avaliar outro método de *gradient boosting*, o *lightGBM*. Paralelamente, este trabalho propôs duas estratégias alternativas para a metodologia de reconciliação ótima baseada em *machine learning* proposta originalmente em @spiliotis_hierarchical_2021.

Os resultados obtidos para o *dataset* ESTBAN mostraram, primeiramente, que não houve uma combinação de método e estratégia que obtivesse melhor performance de maneira consistente ao longo de todos os níveis hierárquicos. Dessa forma, a escolha do método e da estratégia a serem utilizados dependerá do objetivo do pesquisador. Para os níveis ao topo da hierarquia, a combinação correta de método e estratégia de estimação (*elastic net* + *refit*) gerou até 89% de ganho de performance no nível mais agregado, permitindo à instituição financeira maior precisão para tomada de decisão e planejamento estratégico, além de sinalizar maior confiança nas estimativas comunicadas ao mercado e aos investidores. Por outro lado, para os níveis inferiores na estrutura hierárquica, os métodos analíticos se mostraram a melhor escolha. Isso sugere que, com o objetivo de elaboração de metas individuais — seja para as agências ou superintendências regionais —, os métodos analíticos ainda são preferíveis.

Os restultados para o *dataset* ESTBAN também mostram que o resultado da reconciliação ótima é sensível à estratégia utilizada. Apenas na estratégia *refit* que os ganhos de performance foram observados, enquanto nas estratégias *rolling forecast* e *fitted base* os métodos de ML não foram capazes de superar os métodos analíticos.

O mesmo padrão em relação à performance ao logo dos níveis de agregação pôde ser observado no *dataset* TOURISM. Foi possível encontrar uma combinação de método de ML e estratégia capaz de superar os métodos analíticos para os níveis mais agregados, mas não para os níveis mais desagregados. Nesse *dataset*, os métodos de ML superaram os analíticos em todos os níveis de agregação, exceto no mais desagregado, com os métodos *support vector machines* e *elastic net* liderando a performance tanto nas estratégias *rolling forecast* quanto *fitted base*.

Contrariamente aos resultados de @spiliotis_hierarchical_2021, em ambos *datasets*, os métodos de ML baseados em árvore de decisão (*XGBoost*, *ranger* e *lightGBM*) não foram capazes de superar os métodos analíticos em nenhum nível de agregação.

Para pesquisas futuras, pode-se investigar se a performance dos diferentes métodos e estratégias estão relacionadas às características das séries temporais, por exemplo:

- Os efeitos do ruído de previsão: se os diferentes métodos e estratégias exibem aumento ou deterioração de performance quando as previsões individuais são mais ou menos ruidosas (i.e. se a variância do erro das previsões individuais é maior ou menor).
- Os efeitos de correlação entre as séries: se os métodos e estratégias exibem aumento ou deterioração de performance quando as séries temporais no menor nível hierárquico são mais ou menos correlacionadas.
- Os efeitos de componentes sazonais: se os métodos e estratégias exibem aumento ou deterioração de performance quando as séries temporais do menor nível hierárquico possuem ou não componentes sazonais.
- Os efeitos do tamanho da hierarquia: verificar se os métodos e estratégias exibem aumento ou deterioração de performance quando a hierarquia é mais ou menos profunda (i.e. possui mais ou menos níveis hierárquicos).
