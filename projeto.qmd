---
title: ""
format:
    pdf:
        include-in-header: config/preamble.tex
        keep-tex: false
        output-file: render/projeto.pdf
cite-method: biblatex
fontsize: 12pt
geometry: margin=1in
number-sections: true
crossref:
  fig-prefix: "figura"
  eq-prefix: ""
---

```{r config}
#| include = FALSE

# opções
knitr::opts_chunk$set(
    out.width = "70%",
    echo = FALSE
)

# reprodutibilidade
set.seed(1)

# pacotes
library(DiagrammeR)
library(kableExtra)
library(ggplot2)

# tema ggplot
tema = theme_classic() +
    theme(
        text = element_text(family = "serif")
    )

# gerar bibliografia de pacotes
knitr::write_bib(file = "config/packages.bib")

# scripts
source("scripts/hierarq.R")
```

<!-- folha de rosto -->

\newpage
\thispagestyle{empty}

\begin{center}
{\Large \MakeUppercase{\nome\>\sobrenome}}

\vspace{6cm}

\Large \MakeUppercase{\textbf{\titulo}}

\normalsize

\vspace{3cm}
\end{center}

\hspace{7cm}{\begin{minipage}{8.5cm}{
Projeto de dissertação apresentado ao \curso\>da \universidade.\\

Orientador: \parbox[t]{6.0cm}{\orientador}}
\end{minipage}}

\vspace{3cm}

\begin{center}
\cidade\\
\ano
\end{center}

<!-- resumo -->

\newpage
\thispagestyle{empty}
\begin{singlespace}
\noindent \MakeUppercase{\sobrenome}, \nome. \textbf{\titulo}. \ano. \pageref{LastPage} folhas. Projeto de \MakeLowercase{\tipo}\>(\curso) -- \universidade, \cidade, \ano.

\vspace{1pc}
\begin{center}
\textbf{RESUMO}
\end{center}
\vspace{1pc}

\noindent
No máximo 500 palavaras em espaço simples e sem parágrafos. Deve apresentar de forma concisa os objetivos, metodologia e os resultado alcançados, utilizar o verbo na voz ativa. Espaçamento simples, sem recuo de parágrafos.

\vspace{2pc}
\noindent
{\textbf{Palavras-chave}:}  Palavra 1. Palavra 2. Palavra 3. Palavra 4. Palavra 5.

\end{singlespace}

<!-- elementos textuais -->

\setcounter{page}{1}
# INTRODUÇÃO

Em minha pesquisa no mestrado, pretendo trabalhar no problema da reconciliação ótima de séries temporais hierárquicas e agrupadas no contexto probabilístico.

## CONTEXTUALIZAÇÃO DA PESQUISA

Séries temporais hierárquicas são aquelas que podem ser agregadas ou desagregadas naturalmente em uma estrutura aninhada [@hyndman2021]. Para ilustrar, tome a série do Pib brasileiro. Ela pode ser desagregada por estado que, por sua vez, pode ser desagregada por município.

![Séries Hierárquicas](img/hierarq.png){#fig-h}

Essa estrutura pode ser representada por equações para qualquer nível de agregação. Assim, o agregado nacional pode ser representado apenas pelos agregados dos estados, através de \eqref{eq:ha}, ou como o agregado dos municípios \eqref{eq:ha_mun}. Já o agregado para o estado do Espírito Santo é representado por \eqref{eq:haES}.

\begin{align}
y_t &= y_{A,t} + y_{B,t} + y_{C,t} \label{eq:ha} \\
y_t &= y_{AA,t} + y_{AB,t} + y_{AC,t} + y_{BA,t} + y_{BC,t} + y_{CA,t}\label{eq:ha_mun} \\
y_{A,t} &= y_{AA,t} + y_{AB,t} + y_{AC,t} \label{eq:haES}
\end{align}

Por outro lado, o Pib pode ser também desagregado de forma cruzada de acordo com a atividade econômica --- lavoura, rebanho, indústria de transformação, extrativa, bens de capital, bens intermediários, comércio de vestuário, automotivos, serviços etc. Essa estrutura não pode ser desagregada naturalmente de uma única forma, como é a hierarquia de estados e municípios. Não pode ser aninhada por um atributo como a própria geografia. A esse tipo de estrutura dá-se o nome de séries agrupadas.

![Séries Agrupadas](img/agrupadas.png){#fig-a}

Combinando as duas, temos a estrutura de séries hierárquicas agrupadas. Ao contrário da estrutura hierárquica, que só pode ser agregada de uma forma --- como com os municípios abaixo dos estados ---, a adição da estrutura agrupada pode ocorrer tanto acima quanto abaixo da hierárquica.

Na notação matricial, essas estruturas são representadas pelo vetor $\mathbfit{y}_t$ $n$-dimensional com todas as observações no tempo $t$ para todos os níveis da hierarquia, pela matriz de soma $\mathbfit{S}$ de dimensão $n \times m$ que define as equações para todo nível de agregação e pela matriz $\mathbfit{b}_t$ composta pelas séries no nível mais desagregado.

$$
\mathbfit{y}_t=\mathbfit{Sb}_t
$$ {#eq-geral}

Talvez as formas mais intuitivas de se pensar em previsões para esses tipos de estrutura sejam as abordagens *top-down* e *bottom-up*. Na abordagem *top-down*, a previsão para os níveis mais desagregados da hierarquia são determinadas por uma proporção $p_i$ do nível agregado. Para isso, temos de definir uma matriz com todos esses pesos, que, seguindo a formulação de @hyndman2021, chamo de $\mathbfit{G}$. Já a abordagem *bottom-up* parte do raciocínio inverso e define as previsões de cada elemento da estrutura a partir das previsões dos elementos mais desagregados. Para tanto, basta modificar a matriz $\mathbfit{G}$. Então, $\mathbfit{G}$ define a abordagem --- se top-down ou bottom-up ---, e $\mathbfit{S}$ define a maneira da qual as previsões são somadas para formar as equações de previsão para cada elemento da estrutura.

Seja somando as previsões do nível mais desagregado para formar os níveis superiores da hierarquia (*bottom-up*) ou distribuindo proporcionalmente as previsões do nível mais agregado (*top-down*), o vetor $\mathbfit{\tilde{y}}_t$ representa as previsões *coerentes*. Isso significa que as previsões "batem", ou seja, são totalizadas corretamente --- as previsões de cada elemento agregado corresponde ao somatório das previsões dos níveis inferiores da hierarquia. Isso é garantido pela multiplicação das matrizes $\mathbfit{SG}$.

Não fosse essa pré multiplicação, nada garantiria a coerência das previsões. Tomando a esturtura da @fig-h como exemplo, seria um acaso improvável que as previsões do agregado para o estado do Espírito Santo sejam exatamente a soma das previsões individuais de seus municípios. Isso porque cada série pode seguir um processo diferente (e.g., arima) com erros e variâncias distintas.

Os métodos de gerar previsões coerentes a partir de previsões base são chamados de métodos de *reconciliação*. Os métodos de reconciliação tradicionais apresentados, *top-down* e *bottom-up*, utilizam informação limitada. No método *top-down*, utiliza-se apenas informações do nível mais agregado, enquanto na abordagem *bottom-up* utiliza-se apenas as informações dos níveis mais desagregados.

Alternativamente, podemos pensar numa matriz $\mathbfit{G}$ qualquer que utilize toda a informação disponível e tenha algumas propriedades que garantam que as previsões coerentes tenham a menor diferença o possível em relação às previsões base. Esse é o problema de pesquisa trabalhado na *reconciliação ótima*.

# OBJETIVOS

Meu objetivo geral para a dissertação é estudar o problema da reconciliação ótima de previsões pontuais a partir de regressões quantílicas.

Como objetivos específicos, tenho:

1. Estudar métodos para estimação da matriz $\mathbfit{G}$ para qualquer quantil desejado, e não apenas a média;
2. Identificar possíveis vantagens e limitações da abordagem quantílica na reconciliação de previsões pontuais a partir de aplicação do método estudado na previsão de saldos de crédito do Banco do Estado do Espírito Santo SA.

Não está no escopo do estudo os métodos de se obter previsões probabilísticas, ou seja, a estimação da matriz $\hat{y}_{T+h}$ para além de previsões pontuais.

# REVISÃO DA LITERATURA

Previsões pontuais de séries temporais hierárquicas não é um assunto novo. Desde a década de 70, ao menos, pesquisas foram publicadas acerca de abordagens *bottom-up* e *top-down*, suas vantagens e desvantagens, e tentativas de se definir qual é o melhor método^[Uma revisão dessa literatura pode ser encontrada em @athanasopoulos2009.]. Entretanto, é apenas em @hyndman2011 que é formalizada uma abordagem prática que utiliza toda a informação disponível, (i.e. as previsões de todos elementos de todos os níveis da hierarquia) a partir da estimação da matriz $\mathbfit{G}$ via regressão linear por MQG.

Entretanto, para ser capaz de estimar o modelo por MQG, é necessária a matriz de variância-covariância dos erros. @hyndman2011 usam a matriz de erros de coerência, ou seja, a diferença entre as previsões reconciliadas e as previsões base, que tem posto incompleto e não identificada e, portanto, não pode ser estimada. Os autores contornam esse problema adotando no lugar da matriz de variância-covariância dos erros uma matriz diagonal constante, ou seja, assumem variância constante dos erros de reconciliação, e estimam a matriz $\mathbfit{G}$ por MQO.

A estimação por esse método resulta numa reconciliação ótima que depende apenas da matriz $\mathbfit{G}$, ou seja, da estrutura hierárquica, e independe da variância e covariância das previsões base $\mathbfit{\hat{y}_{T+h}}$ --- o que não é uma conclusão satisfatória.

@hyndman2016 tentam aperfeiçoar o método usando as variâncias das previsões base estimadas (dentro da amostra) como estimativa para a matriz de variância-covariância dos erros de conciliação, de forma a as utilizar como pesos e realizar a reconciliação ótima por MQP. Assim, previsões base mais acuradas têm peso maior do que as mais ruidosas. Entretanto, não fornecem justificativa teórica para usar a diagonal da matriz de variância-covariância de $\mathbfit{\hat{e}_{t}}$.

@wickramasuriya2019 argumentam que o que de fato interessa é que as previsões reconciliadas tenham o menor erro. Então, corrigem a abordagem de reconciliação ótima para o objetivo de minimização dos erros das previsões reconciliadas $\mathbfit{\tilde{y}_{t+h}}$, ao invés dos erros das previsões base $\mathbfit{\hat{y}_{t+h}}$. Dado que isso implica na minimização da variância de $\mathbfit{\tilde{e}_{t+h}}$, ou seja, na minimização do somatório da diagonal, o traço, da matriz de variância-covariância de $\mathbfit{\tilde{e}_{t+h}}$, eles chamaram esse método de MinT (*Minimum Trace*). Paralelamente, usam desigualdade triangular para demonstrar que as previsões reconciliadas obtidas por esse método são ao menos tão boas quanto as previsões base.

@panagiotelis2021 reinterpreta a literatura de coerência e reconciliação de previsões pontuais a partir de uma abordagem geométrica, trazendo provas alternativas para conclusões anteriores ao mesmo tempo em que fornece novos teoremas. Além disso, @panagiotelis2021 então estende essa interpretação geométrica para o contexto probabilístico, fornecendo métodos paramétricos e não paramétricos (via *bootstrapping*) para reconciliação de previsões probabilísticas, ou seja, para reconciliar previsões $\hat{y}_t$ obtidas a partir de toda a distribuição, e não apenas a média.

# METODOLOGIA

Para atingir os objetivos, será realizada pesquisa bibliográfica 

# CRONOGRAMA

# REFERÊNCIAS {-}